{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation Data\n",
    "- when testing different hyperparameters, we should not optimize them based on the training data, which will further introduce bias toward the training data and cause overfitting to the training data\n",
    "- should also not tune hyperparamaters on the testing data either, as this data should be completely unseen, and use only to test performance of the model\n",
    "- Thus, should tune hyperparameters using a validation dataset\n",
    "- best case scenario is that we have enough data to have separate training, validation, and testing datasets\n",
    "- if we do not have enough data, have two options:\n",
    "1) temporarily split the training dataset into a smaller training set and a validation set for hyperparameter tuning. Then once we have the final hyperparameters, train the model using those hyper parameters on the full training dataset (the smaller training set + smaller validation set). Will still have a separate training dataset. This is better for a medium sized datset.\n",
    "2) Cross Validation - for when we have a small dataset and cannot afford to save any for a separate smaller validation set. Split the training dataset into smaller pieces, and leave one out for validation. Then iterate over this split. So for example, if we split into five pieces, train on four, then validate one. And we rotate over the validation set. So train on first four, validate on five. Then train on one to three and five, and validate four. So on and so forth. This is called k-fold cross validation. Choose the best hyperparameters from the set of runs through the data. Unless training is very fast, its better to pick some hyperparameters that we think will work well and refine those rather than checking all possible combinations. Can repeat this process iteratively as many times as we like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
