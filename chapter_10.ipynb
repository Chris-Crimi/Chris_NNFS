{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent\n",
    "- Stochastic Gradient Descent - fitting single sample at a time\n",
    "- vanilla gradient descent, gradient descent, batch gradient descent - fitting whole dataset at once\n",
    "- mini batch dataset - fit smaller (mini) batches of data instead of all data at once\n",
    "- These terms can get confusing. For the purpose of the book we will call mini batches batches \n",
    "- some call it stochastic gradient descent regardless of batch size/single sample\n",
    "\n",
    "- to implement gradient descent, need a learing rate and the calculated gradients of loss function with respect to parameters. To get the parameter update amounts just multiply -learning rate * gradients, then add to the parameters. Learning rate is negated because we are trying to find minimum, so stepping towards lowest loss\n",
    "- see optimizer object below - in previous work we stored the layer weights and biases gradients in the layer objects as attributes so we can now make use of & modify them via the optimzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer_SGD:\n",
    "# Initialize optimizer - set settings,\n",
    "# learning rate of 1. is default for this optimizer\n",
    "    def __init__(self, learning_rate=1.0):\n",
    "        self.learning_rate = learning_rate\n",
    "    # Update parameters\n",
    "    def update_params(self, layer):\n",
    "        layer.weights += -self.learning_rate * layer.dweights\n",
    "        layer.biases += -self.learning_rate * layer.dbiases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic network training using SGD optimizer\n",
    "- epoch - a full pass through the training data, including forwards and backwards\n",
    "- typically models are trained over multiple epochs, but obviously the less the better\n",
    "- here it is implemented via for loop where each epoch is 1 interation of the loop, including a forward and backward pass, so do that 10000x\n",
    "- for this intial run, we chose a learning rate of 1, (it is the default)\n",
    "- run the final cell in this workbook with full network code to use this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 0.360, loss: 1.099\n",
      "epoch: 100, acc: 0.400, loss: 1.087\n",
      "epoch: 200, acc: 0.417, loss: 1.077\n",
      "epoch: 300, acc: 0.413, loss: 1.076\n",
      "epoch: 400, acc: 0.400, loss: 1.074\n",
      "epoch: 500, acc: 0.403, loss: 1.071\n",
      "epoch: 600, acc: 0.417, loss: 1.067\n",
      "epoch: 700, acc: 0.440, loss: 1.062\n",
      "epoch: 800, acc: 0.457, loss: 1.055\n",
      "epoch: 900, acc: 0.410, loss: 1.062\n",
      "epoch: 1000, acc: 0.407, loss: 1.058\n",
      "epoch: 1100, acc: 0.407, loss: 1.057\n",
      "epoch: 1200, acc: 0.403, loss: 1.064\n",
      "epoch: 1300, acc: 0.427, loss: 1.051\n",
      "epoch: 1400, acc: 0.443, loss: 1.067\n",
      "epoch: 1500, acc: 0.400, loss: 1.058\n",
      "epoch: 1600, acc: 0.420, loss: 1.070\n",
      "epoch: 1700, acc: 0.410, loss: 1.049\n",
      "epoch: 1800, acc: 0.460, loss: 1.040\n",
      "epoch: 1900, acc: 0.483, loss: 1.033\n",
      "epoch: 2000, acc: 0.403, loss: 1.038\n",
      "epoch: 2100, acc: 0.447, loss: 1.022\n",
      "epoch: 2200, acc: 0.467, loss: 1.023\n",
      "epoch: 2300, acc: 0.437, loss: 1.005\n",
      "epoch: 2400, acc: 0.497, loss: 0.993\n",
      "epoch: 2500, acc: 0.513, loss: 0.981\n",
      "epoch: 2600, acc: 0.453, loss: 0.991\n",
      "epoch: 2700, acc: 0.513, loss: 0.980\n",
      "epoch: 2800, acc: 0.523, loss: 0.985\n",
      "epoch: 2900, acc: 0.507, loss: 0.993\n",
      "epoch: 3000, acc: 0.483, loss: 0.973\n",
      "epoch: 3100, acc: 0.493, loss: 0.973\n",
      "epoch: 3200, acc: 0.463, loss: 0.987\n",
      "epoch: 3300, acc: 0.510, loss: 0.992\n",
      "epoch: 3400, acc: 0.533, loss: 0.969\n",
      "epoch: 3500, acc: 0.547, loss: 0.994\n",
      "epoch: 3600, acc: 0.487, loss: 0.966\n",
      "epoch: 3700, acc: 0.493, loss: 0.969\n",
      "epoch: 3800, acc: 0.510, loss: 0.971\n",
      "epoch: 3900, acc: 0.540, loss: 0.989\n",
      "epoch: 4000, acc: 0.533, loss: 0.956\n",
      "epoch: 4100, acc: 0.567, loss: 0.988\n",
      "epoch: 4200, acc: 0.497, loss: 0.958\n",
      "epoch: 4300, acc: 0.500, loss: 0.972\n",
      "epoch: 4400, acc: 0.520, loss: 0.968\n",
      "epoch: 4500, acc: 0.550, loss: 0.984\n",
      "epoch: 4600, acc: 0.543, loss: 0.955\n",
      "epoch: 4700, acc: 0.563, loss: 1.006\n",
      "epoch: 4800, acc: 0.503, loss: 0.966\n",
      "epoch: 4900, acc: 0.483, loss: 0.965\n",
      "epoch: 5000, acc: 0.510, loss: 0.985\n",
      "epoch: 5100, acc: 0.553, loss: 0.953\n",
      "epoch: 5200, acc: 0.573, loss: 0.994\n",
      "epoch: 5300, acc: 0.500, loss: 0.969\n",
      "epoch: 5400, acc: 0.503, loss: 0.958\n",
      "epoch: 5500, acc: 0.517, loss: 0.979\n",
      "epoch: 5600, acc: 0.553, loss: 0.947\n",
      "epoch: 5700, acc: 0.567, loss: 0.959\n",
      "epoch: 5800, acc: 0.583, loss: 0.970\n",
      "epoch: 5900, acc: 0.547, loss: 0.950\n",
      "epoch: 6000, acc: 0.517, loss: 0.931\n",
      "epoch: 6100, acc: 0.577, loss: 0.966\n",
      "epoch: 6200, acc: 0.560, loss: 0.923\n",
      "epoch: 6300, acc: 0.590, loss: 0.955\n",
      "epoch: 6400, acc: 0.550, loss: 0.926\n",
      "epoch: 6500, acc: 0.547, loss: 0.926\n",
      "epoch: 6600, acc: 0.563, loss: 0.923\n",
      "epoch: 6700, acc: 0.593, loss: 0.875\n",
      "epoch: 6800, acc: 0.587, loss: 0.928\n",
      "epoch: 6900, acc: 0.613, loss: 0.874\n",
      "epoch: 7000, acc: 0.580, loss: 0.884\n",
      "epoch: 7100, acc: 0.610, loss: 0.859\n",
      "epoch: 7200, acc: 0.583, loss: 0.881\n",
      "epoch: 7300, acc: 0.623, loss: 0.912\n",
      "epoch: 7400, acc: 0.620, loss: 0.852\n",
      "epoch: 7500, acc: 0.617, loss: 0.877\n",
      "epoch: 7600, acc: 0.570, loss: 0.884\n",
      "epoch: 7700, acc: 0.597, loss: 0.840\n",
      "epoch: 7800, acc: 0.583, loss: 0.889\n",
      "epoch: 7900, acc: 0.643, loss: 0.897\n",
      "epoch: 8000, acc: 0.643, loss: 0.840\n",
      "epoch: 8100, acc: 0.630, loss: 0.854\n",
      "epoch: 8200, acc: 0.630, loss: 0.858\n",
      "epoch: 8300, acc: 0.587, loss: 0.873\n",
      "epoch: 8400, acc: 0.577, loss: 0.873\n",
      "epoch: 8500, acc: 0.607, loss: 0.874\n",
      "epoch: 8600, acc: 0.633, loss: 0.873\n",
      "epoch: 8700, acc: 0.617, loss: 0.845\n",
      "epoch: 8800, acc: 0.610, loss: 0.835\n",
      "epoch: 8900, acc: 0.617, loss: 0.846\n",
      "epoch: 9000, acc: 0.610, loss: 0.870\n",
      "epoch: 9100, acc: 0.603, loss: 0.934\n",
      "epoch: 9200, acc: 0.623, loss: 0.905\n",
      "epoch: 9300, acc: 0.643, loss: 0.866\n",
      "epoch: 9400, acc: 0.643, loss: 0.837\n",
      "epoch: 9500, acc: 0.590, loss: 0.865\n",
      "epoch: 9600, acc: 0.627, loss: 0.863\n",
      "epoch: 9700, acc: 0.630, loss: 0.830\n",
      "epoch: 9800, acc: 0.663, loss: 0.844\n",
      "epoch: 9900, acc: 0.627, loss: 0.820\n",
      "epoch: 10000, acc: 0.633, loss: 0.848\n"
     ]
    }
   ],
   "source": [
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "import numpy as np\n",
    "nnfs.init()\n",
    "\n",
    "###NOTE: run full network code in final cell of this workbook so that this example works\n",
    "\n",
    "# Create dataset\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# Create Dense layer with 2 input features and 64 output values\n",
    "dense1 = Layer_Dense(2, 64)\n",
    "\n",
    "# Create ReLU activation (to be used with Dense layer):\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "# Create second Dense layer with 64 input features (as we take output\n",
    "# of previous layer here) and 3 output values (output values)\n",
    "dense2 = Layer_Dense(64, 3)\n",
    "\n",
    "# Create Softmax classifier's combined loss and activation\n",
    "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = Optimizer_SGD()\n",
    "# Train in loop\n",
    "for epoch in range(10001):\n",
    "    # Perform a forward pass of our training data through this layer\n",
    "    dense1.forward(X)\n",
    "    \n",
    "    # Perform a forward pass through activation function\n",
    "    # takes the output of first dense layer here\n",
    "    activation1.forward(dense1.output)\n",
    "    \n",
    "    # Perform a forward pass through second Dense layer\n",
    "    # takes outputs of activation function of first layer as inputs\n",
    "    dense2.forward(activation1.output)\n",
    "    \n",
    "    # Perform a forward pass through the activation/loss function\n",
    "    # takes the output of second dense layer here and returns loss\n",
    "    loss = loss_activation.forward(dense2.output, y)\n",
    "\n",
    "    # Calculate accuracy from output of activation2 and targets\n",
    "    # calculate values along first axis\n",
    "    predictions = np.argmax(loss_activation.output, axis=1)\n",
    "    if len(y.shape) == 2:\n",
    "        y = np.argmax(y, axis=1)\n",
    "    accuracy = np.mean(predictions==y)\n",
    "    \n",
    "    if not epoch % 100: #only every hundredth epoch\n",
    "        print(f'epoch: {epoch}, ' +\n",
    "        f'acc: {accuracy:.3f}, ' +\n",
    "        f'loss: {loss:.3f}')\n",
    "    \n",
    "    # Backward pass\n",
    "    loss_activation.backward(loss_activation.output, y)\n",
    "    dense2.backward(loss_activation.dinputs)\n",
    "    activation1.backward(dense2.dinputs)\n",
    "    dense1.backward(activation1.dinputs)\n",
    "    \n",
    "    # Update weights and biases\n",
    "    optimizer.update_params(dense1)\n",
    "    optimizer.update_params(dense2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the output of this intial training method showed some learing (accuracy ~63%), but loss did not drop \n",
    "- the visualiztion of this training: https://nnfs.io/pup\n",
    "- in the visualization, there is a \"flashy wiggle\" effect, indicating the learning rate may be too high. We can also tell via the loss, which does not decrease smoothly, but bounces around, (i.e. the loss decreases between epochs, then increases again between other epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Learning Rate\n",
    "- in most cases applying the full negative gradient to the parameters is too big of a step, as the gradient is continously changing (and we are applying a point estimate of a tangent function). So a big jump may result in jumping over the steepest areas of the function instead of more closely hugging to the function's curvature.\n",
    "- small steps make sure we follow the direction of steepest descent, hugging more closely to the function curve by not jumping too much. But too small is bad too - takes longer to arive at optimal parameters and more prone to getting stuck in local minimums, the lowest point of a function in a given x range (vs global minimum - the lowest possible y value a function can output)\n",
    "- ideal global minimum for ANNs is a loss of 0 - however this is typically not achieved. You know you are stuck in some local minumum if the loss is not low/close to 0\n",
    "- Gradient descent algo follows the direction of steepest descent, no matter how large or small it is. So if you are near a local minimum, this is what causes it to get stcuk because graidents near local minimum are lower, causing smaller parameter adjustment\n",
    "- too low learning rate can cause learning stagnation - stuck in local minimum\n",
    "- too high learning rate can cause gradient explosion - where gradient updates cause model loss to rise instead of fall. Eventually loss/gradients become so big that they cannot be stored in floating point, causing error. Can be costly if model has taken a while to train, then waste of time and computing resources\n",
    "- with just learning rate, need to select an learning rate that is not too high or too low for the reasons discussed above. Too high and will cause loss to bounce around/gradient explosion, too low and the model will learn too slow.\n",
    "- alternatives to just setting learning rate are learning rate decay and momentum\n",
    "- setting these factors are called hyper parameters, and setting them appropriately requires experience, it is difficult to prescribe anything. Have to see how model performs with different hyperparameters and adjust from there.\n",
    "- see code example below for lower learning rate - BE SURE TO RUN FINAL CELL SO THE OBJECTS WORK\n",
    "- in the code example, setting learning rate to .85 causes slightly higher accuracy, and slightly lower loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 0.360, loss: 1.099\n",
      "epoch: 100, acc: 0.403, loss: 1.091\n",
      "epoch: 200, acc: 0.410, loss: 1.078\n",
      "epoch: 300, acc: 0.423, loss: 1.077\n",
      "epoch: 400, acc: 0.413, loss: 1.075\n",
      "epoch: 500, acc: 0.400, loss: 1.074\n",
      "epoch: 600, acc: 0.410, loss: 1.071\n",
      "epoch: 700, acc: 0.417, loss: 1.067\n",
      "epoch: 800, acc: 0.440, loss: 1.064\n",
      "epoch: 900, acc: 0.443, loss: 1.057\n",
      "epoch: 1000, acc: 0.420, loss: 1.050\n",
      "epoch: 1100, acc: 0.397, loss: 1.061\n",
      "epoch: 1200, acc: 0.387, loss: 1.060\n",
      "epoch: 1300, acc: 0.420, loss: 1.061\n",
      "epoch: 1400, acc: 0.460, loss: 1.055\n",
      "epoch: 1500, acc: 0.390, loss: 1.057\n",
      "epoch: 1600, acc: 0.450, loss: 1.072\n",
      "epoch: 1700, acc: 0.400, loss: 1.049\n",
      "epoch: 1800, acc: 0.423, loss: 1.039\n",
      "epoch: 1900, acc: 0.387, loss: 1.059\n",
      "epoch: 2000, acc: 0.437, loss: 1.053\n",
      "epoch: 2100, acc: 0.443, loss: 1.026\n",
      "epoch: 2200, acc: 0.377, loss: 1.050\n",
      "epoch: 2300, acc: 0.433, loss: 1.016\n",
      "epoch: 2400, acc: 0.460, loss: 1.000\n",
      "epoch: 2500, acc: 0.493, loss: 1.010\n",
      "epoch: 2600, acc: 0.527, loss: 0.998\n",
      "epoch: 2700, acc: 0.523, loss: 0.977\n",
      "epoch: 2800, acc: 0.507, loss: 0.967\n",
      "epoch: 2900, acc: 0.487, loss: 0.993\n",
      "epoch: 3000, acc: 0.520, loss: 0.987\n",
      "epoch: 3100, acc: 0.540, loss: 0.980\n",
      "epoch: 3200, acc: 0.543, loss: 0.950\n",
      "epoch: 3300, acc: 0.530, loss: 0.952\n",
      "epoch: 3400, acc: 0.543, loss: 0.970\n",
      "epoch: 3500, acc: 0.530, loss: 0.942\n",
      "epoch: 3600, acc: 0.543, loss: 0.955\n",
      "epoch: 3700, acc: 0.557, loss: 0.961\n",
      "epoch: 3800, acc: 0.543, loss: 0.941\n",
      "epoch: 3900, acc: 0.560, loss: 0.951\n",
      "epoch: 4000, acc: 0.543, loss: 0.952\n",
      "epoch: 4100, acc: 0.543, loss: 0.935\n",
      "epoch: 4200, acc: 0.517, loss: 0.933\n",
      "epoch: 4300, acc: 0.557, loss: 0.949\n",
      "epoch: 4400, acc: 0.537, loss: 0.934\n",
      "epoch: 4500, acc: 0.590, loss: 0.955\n",
      "epoch: 4600, acc: 0.590, loss: 0.967\n",
      "epoch: 4700, acc: 0.517, loss: 0.941\n",
      "epoch: 4800, acc: 0.510, loss: 0.964\n",
      "epoch: 4900, acc: 0.553, loss: 0.942\n",
      "epoch: 5000, acc: 0.510, loss: 0.932\n",
      "epoch: 5100, acc: 0.543, loss: 0.937\n",
      "epoch: 5200, acc: 0.587, loss: 0.952\n",
      "epoch: 5300, acc: 0.587, loss: 0.970\n",
      "epoch: 5400, acc: 0.543, loss: 0.941\n",
      "epoch: 5500, acc: 0.527, loss: 0.948\n",
      "epoch: 5600, acc: 0.547, loss: 0.917\n",
      "epoch: 5700, acc: 0.603, loss: 0.966\n",
      "epoch: 5800, acc: 0.553, loss: 0.944\n",
      "epoch: 5900, acc: 0.533, loss: 0.936\n",
      "epoch: 6000, acc: 0.577, loss: 0.970\n",
      "epoch: 6100, acc: 0.557, loss: 0.937\n",
      "epoch: 6200, acc: 0.603, loss: 0.959\n",
      "epoch: 6300, acc: 0.530, loss: 0.941\n",
      "epoch: 6400, acc: 0.577, loss: 0.936\n",
      "epoch: 6500, acc: 0.540, loss: 0.932\n",
      "epoch: 6600, acc: 0.590, loss: 0.961\n",
      "epoch: 6700, acc: 0.550, loss: 0.906\n",
      "epoch: 6800, acc: 0.570, loss: 0.950\n",
      "epoch: 6900, acc: 0.600, loss: 0.958\n",
      "epoch: 7000, acc: 0.523, loss: 0.926\n",
      "epoch: 7100, acc: 0.577, loss: 0.941\n",
      "epoch: 7200, acc: 0.550, loss: 0.921\n",
      "epoch: 7300, acc: 0.593, loss: 0.943\n",
      "epoch: 7400, acc: 0.593, loss: 0.940\n",
      "epoch: 7500, acc: 0.557, loss: 0.907\n",
      "epoch: 7600, acc: 0.590, loss: 0.949\n",
      "epoch: 7700, acc: 0.590, loss: 0.935\n",
      "epoch: 7800, acc: 0.563, loss: 0.932\n",
      "epoch: 7900, acc: 0.603, loss: 0.929\n",
      "epoch: 8000, acc: 0.557, loss: 0.913\n",
      "epoch: 8100, acc: 0.590, loss: 0.953\n",
      "epoch: 8200, acc: 0.587, loss: 0.894\n",
      "epoch: 8300, acc: 0.567, loss: 0.939\n",
      "epoch: 8400, acc: 0.580, loss: 0.910\n",
      "epoch: 8500, acc: 0.580, loss: 0.920\n",
      "epoch: 8600, acc: 0.587, loss: 0.887\n",
      "epoch: 8700, acc: 0.617, loss: 0.909\n",
      "epoch: 8800, acc: 0.623, loss: 0.853\n",
      "epoch: 8900, acc: 0.613, loss: 0.862\n",
      "epoch: 9000, acc: 0.623, loss: 0.864\n",
      "epoch: 9100, acc: 0.597, loss: 0.860\n",
      "epoch: 9200, acc: 0.630, loss: 0.842\n",
      "epoch: 9300, acc: 0.613, loss: 0.885\n",
      "epoch: 9400, acc: 0.603, loss: 0.893\n",
      "epoch: 9500, acc: 0.647, loss: 0.829\n",
      "epoch: 9600, acc: 0.623, loss: 0.836\n",
      "epoch: 9700, acc: 0.610, loss: 0.863\n",
      "epoch: 9800, acc: 0.633, loss: 0.848\n",
      "epoch: 9900, acc: 0.647, loss: 0.819\n",
      "epoch: 10000, acc: 0.657, loss: 0.816\n"
     ]
    }
   ],
   "source": [
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "import numpy as np\n",
    "nnfs.init()\n",
    "\n",
    "###NOTE: run full network code in final cell of this workbook so that this example works\n",
    "\n",
    "# Create dataset\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# Create Dense layer with 2 input features and 64 output values\n",
    "dense1 = Layer_Dense(2, 64)\n",
    "\n",
    "# Create ReLU activation (to be used with Dense layer):\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "# Create second Dense layer with 64 input features (as we take output\n",
    "# of previous layer here) and 3 output values (output values)\n",
    "dense2 = Layer_Dense(64, 3)\n",
    "\n",
    "# Create Softmax classifier's combined loss and activation\n",
    "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = Optimizer_SGD(learning_rate=.85)\n",
    "# Train in loop\n",
    "for epoch in range(10001):\n",
    "    # Perform a forward pass of our training data through this layer\n",
    "    dense1.forward(X)\n",
    "    \n",
    "    # Perform a forward pass through activation function\n",
    "    # takes the output of first dense layer here\n",
    "    activation1.forward(dense1.output)\n",
    "    \n",
    "    # Perform a forward pass through second Dense layer\n",
    "    # takes outputs of activation function of first layer as inputs\n",
    "    dense2.forward(activation1.output)\n",
    "    \n",
    "    # Perform a forward pass through the activation/loss function\n",
    "    # takes the output of second dense layer here and returns loss\n",
    "    loss = loss_activation.forward(dense2.output, y)\n",
    "\n",
    "    # Calculate accuracy from output of activation2 and targets\n",
    "    # calculate values along first axis\n",
    "    predictions = np.argmax(loss_activation.output, axis=1)\n",
    "    if len(y.shape) == 2:\n",
    "        y = np.argmax(y, axis=1)\n",
    "    accuracy = np.mean(predictions==y)\n",
    "    \n",
    "    if not epoch % 100: #only every hundredth epoch\n",
    "        print(f'epoch: {epoch}, ' +\n",
    "        f'acc: {accuracy:.3f}, ' +\n",
    "        f'loss: {loss:.3f}')\n",
    "    \n",
    "    # Backward pass\n",
    "    loss_activation.backward(loss_activation.output, y)\n",
    "    dense2.backward(loss_activation.dinputs)\n",
    "    activation1.backward(dense2.dinputs)\n",
    "    dense1.backward(activation1.dinputs)\n",
    "    \n",
    "    # Update weights and biases\n",
    "    optimizer.update_params(dense1)\n",
    "    optimizer.update_params(dense2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Rate Decay\n",
    " - general idea is the start with some learning rate at beginning of training and decrease it during training\n",
    " - One way - monitor loss across each epoch and adjust learning rate if there is learning stagnation (ie. loss curve is flattening, rate too low) or jumping in loss (rate too high). Can be programmed or just done manually\n",
    " - Can also use a decay rate that decreases the learning rate per batch or per epoch, such as a 1/t decay or exponential decay.\n",
    " - we will use learning rate decay, specifically: starting_learning rate * (1 / (1+ learning_rate_decay * step_number)). So the larger the step number (scaled by the decay factor) the lower the learning rate. This form also ensure that we do not accidently increase learning rate by divinding by a value less than 1, hence the adding 1.\n",
    " - See below for new optimizer class with learning rate decay\n",
    " - decay is is defualt 0, and if decay is not 0, then we update it with the steps\n",
    " - we keep track of iterations, though not sure if it is necessary if epoch/batches are via range function. I guess it makes it more self-contained, and if you are not looping with numbers then it would be good to internally count iterations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer_SGD:\n",
    "# Initialize optimizer - set settings,\n",
    "# learning rate of 1. is default for this optimizer\n",
    "    def __init__(self, learning_rate=1., decay=0.):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "    # Call once before any parameter updates\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * (1. / (1. + self.decay*self.iterations))\n",
    "    # Update parameters\n",
    "    def update_params(self, layer):\n",
    "        layer.weights += -self.current_learning_rate * layer.dweights\n",
    "        layer.biases += -self.current_learning_rate * layer.dbiases\n",
    "    # Call once after any parameter updates\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traning with Learning Rate\n",
    "- trial and error - learning rate decay of 1e-2 was too high, that is the rate dropped too fast and the model got stuck in local minimum. (higher decay causes larger denominator because we multiply decay by step size), 1e-3 is better, getting to our best accuracy/loss so far. This assumes learning rate of 1.\n",
    "- be sure to run optimzier object cell above and last cell in notebook with all prerequisite code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 0.360, loss: 1.099\n",
      "epoch: 100, acc: 0.400, loss: 1.088\n",
      "epoch: 200, acc: 0.423, loss: 1.078\n",
      "epoch: 300, acc: 0.423, loss: 1.076\n",
      "epoch: 400, acc: 0.420, loss: 1.076\n",
      "epoch: 500, acc: 0.403, loss: 1.074\n",
      "epoch: 600, acc: 0.403, loss: 1.072\n",
      "epoch: 700, acc: 0.410, loss: 1.070\n",
      "epoch: 800, acc: 0.410, loss: 1.068\n",
      "epoch: 900, acc: 0.427, loss: 1.066\n",
      "epoch: 1000, acc: 0.440, loss: 1.063\n",
      "epoch: 1100, acc: 0.440, loss: 1.059\n",
      "epoch: 1200, acc: 0.447, loss: 1.056\n",
      "epoch: 1300, acc: 0.440, loss: 1.052\n",
      "epoch: 1400, acc: 0.427, loss: 1.048\n",
      "epoch: 1500, acc: 0.417, loss: 1.040\n",
      "epoch: 1600, acc: 0.423, loss: 1.033\n",
      "epoch: 1700, acc: 0.450, loss: 1.025\n",
      "epoch: 1800, acc: 0.470, loss: 1.017\n",
      "epoch: 1900, acc: 0.460, loss: 1.008\n",
      "epoch: 2000, acc: 0.463, loss: 1.000\n",
      "epoch: 2100, acc: 0.490, loss: 1.005\n",
      "epoch: 2200, acc: 0.467, loss: 1.014\n",
      "epoch: 2300, acc: 0.483, loss: 1.014\n",
      "epoch: 2400, acc: 0.490, loss: 1.012\n",
      "epoch: 2500, acc: 0.493, loss: 1.009\n",
      "epoch: 2600, acc: 0.497, loss: 1.005\n",
      "epoch: 2700, acc: 0.487, loss: 1.004\n",
      "epoch: 2800, acc: 0.483, loss: 0.999\n",
      "epoch: 2900, acc: 0.493, loss: 0.995\n",
      "epoch: 3000, acc: 0.490, loss: 0.991\n",
      "epoch: 3100, acc: 0.490, loss: 0.987\n",
      "epoch: 3200, acc: 0.493, loss: 0.983\n",
      "epoch: 3300, acc: 0.497, loss: 0.978\n",
      "epoch: 3400, acc: 0.493, loss: 0.974\n",
      "epoch: 3500, acc: 0.507, loss: 0.970\n",
      "epoch: 3600, acc: 0.530, loss: 0.966\n",
      "epoch: 3700, acc: 0.523, loss: 0.960\n",
      "epoch: 3800, acc: 0.527, loss: 0.956\n",
      "epoch: 3900, acc: 0.533, loss: 0.950\n",
      "epoch: 4000, acc: 0.533, loss: 0.946\n",
      "epoch: 4100, acc: 0.547, loss: 0.943\n",
      "epoch: 4200, acc: 0.550, loss: 0.937\n",
      "epoch: 4300, acc: 0.553, loss: 0.933\n",
      "epoch: 4400, acc: 0.557, loss: 0.929\n",
      "epoch: 4500, acc: 0.560, loss: 0.924\n",
      "epoch: 4600, acc: 0.567, loss: 0.919\n",
      "epoch: 4700, acc: 0.567, loss: 0.915\n",
      "epoch: 4800, acc: 0.577, loss: 0.911\n",
      "epoch: 4900, acc: 0.573, loss: 0.906\n",
      "epoch: 5000, acc: 0.577, loss: 0.900\n",
      "epoch: 5100, acc: 0.583, loss: 0.897\n",
      "epoch: 5200, acc: 0.587, loss: 0.892\n",
      "epoch: 5300, acc: 0.590, loss: 0.889\n",
      "epoch: 5400, acc: 0.593, loss: 0.886\n",
      "epoch: 5500, acc: 0.597, loss: 0.881\n",
      "epoch: 5600, acc: 0.617, loss: 0.876\n",
      "epoch: 5700, acc: 0.617, loss: 0.872\n",
      "epoch: 5800, acc: 0.623, loss: 0.868\n",
      "epoch: 5900, acc: 0.623, loss: 0.864\n",
      "epoch: 6000, acc: 0.633, loss: 0.860\n",
      "epoch: 6100, acc: 0.630, loss: 0.856\n",
      "epoch: 6200, acc: 0.640, loss: 0.852\n",
      "epoch: 6300, acc: 0.647, loss: 0.849\n",
      "epoch: 6400, acc: 0.653, loss: 0.845\n",
      "epoch: 6500, acc: 0.657, loss: 0.843\n",
      "epoch: 6600, acc: 0.640, loss: 0.839\n",
      "epoch: 6700, acc: 0.617, loss: 0.832\n",
      "epoch: 6800, acc: 0.657, loss: 0.829\n",
      "epoch: 6900, acc: 0.667, loss: 0.832\n",
      "epoch: 7000, acc: 0.663, loss: 0.827\n",
      "epoch: 7100, acc: 0.660, loss: 0.825\n",
      "epoch: 7200, acc: 0.673, loss: 0.821\n",
      "epoch: 7300, acc: 0.657, loss: 0.817\n",
      "epoch: 7400, acc: 0.667, loss: 0.814\n",
      "epoch: 7500, acc: 0.657, loss: 0.811\n",
      "epoch: 7600, acc: 0.653, loss: 0.808\n",
      "epoch: 7700, acc: 0.647, loss: 0.806\n",
      "epoch: 7800, acc: 0.647, loss: 0.804\n",
      "epoch: 7900, acc: 0.643, loss: 0.802\n",
      "epoch: 8000, acc: 0.647, loss: 0.799\n",
      "epoch: 8100, acc: 0.647, loss: 0.797\n",
      "epoch: 8200, acc: 0.640, loss: 0.796\n",
      "epoch: 8300, acc: 0.643, loss: 0.794\n",
      "epoch: 8400, acc: 0.643, loss: 0.793\n",
      "epoch: 8500, acc: 0.637, loss: 0.791\n",
      "epoch: 8600, acc: 0.640, loss: 0.790\n",
      "epoch: 8700, acc: 0.640, loss: 0.788\n",
      "epoch: 8800, acc: 0.643, loss: 0.787\n",
      "epoch: 8900, acc: 0.643, loss: 0.785\n",
      "epoch: 9000, acc: 0.647, loss: 0.784\n",
      "epoch: 9100, acc: 0.647, loss: 0.782\n",
      "epoch: 9200, acc: 0.647, loss: 0.781\n",
      "epoch: 9300, acc: 0.643, loss: 0.780\n",
      "epoch: 9400, acc: 0.650, loss: 0.778\n",
      "epoch: 9500, acc: 0.653, loss: 0.777\n",
      "epoch: 9600, acc: 0.657, loss: 0.776\n",
      "epoch: 9700, acc: 0.657, loss: 0.774\n",
      "epoch: 9800, acc: 0.663, loss: 0.773\n",
      "epoch: 9900, acc: 0.663, loss: 0.772\n",
      "epoch: 10000, acc: 0.667, loss: 0.771\n"
     ]
    }
   ],
   "source": [
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "import numpy as np\n",
    "nnfs.init()\n",
    "\n",
    "###NOTE: run full network code in final cell of this workbook so that this example works\n",
    "\n",
    "# Create dataset\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# Create Dense layer with 2 input features and 64 output values\n",
    "dense1 = Layer_Dense(2, 64)\n",
    "\n",
    "# Create ReLU activation (to be used with Dense layer):\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "# Create second Dense layer with 64 input features (as we take output\n",
    "# of previous layer here) and 3 output values (output values)\n",
    "dense2 = Layer_Dense(64, 3)\n",
    "\n",
    "# Create Softmax classifier's combined loss and activation\n",
    "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = Optimizer_SGD(decay=1e-3)\n",
    "# Train in loop\n",
    "for epoch in range(10001):\n",
    "    # Perform a forward pass of our training data through this layer\n",
    "    dense1.forward(X)\n",
    "    \n",
    "    # Perform a forward pass through activation function\n",
    "    # takes the output of first dense layer here\n",
    "    activation1.forward(dense1.output)\n",
    "    \n",
    "    # Perform a forward pass through second Dense layer\n",
    "    # takes outputs of activation function of first layer as inputs\n",
    "    dense2.forward(activation1.output)\n",
    "    \n",
    "    # Perform a forward pass through the activation/loss function\n",
    "    # takes the output of second dense layer here and returns loss\n",
    "    loss = loss_activation.forward(dense2.output, y)\n",
    "\n",
    "    # Calculate accuracy from output of activation2 and targets\n",
    "    # calculate values along first axis\n",
    "    predictions = np.argmax(loss_activation.output, axis=1)\n",
    "    if len(y.shape) == 2:\n",
    "        y = np.argmax(y, axis=1)\n",
    "    accuracy = np.mean(predictions==y)\n",
    "    \n",
    "    if not epoch % 100: #only every hundredth epoch\n",
    "        print(f'epoch: {epoch}, ' +\n",
    "        f'acc: {accuracy:.3f}, ' +\n",
    "        f'loss: {loss:.3f}')\n",
    "    \n",
    "    # Backward pass\n",
    "    loss_activation.backward(loss_activation.output, y)\n",
    "    dense2.backward(loss_activation.dinputs)\n",
    "    activation1.backward(dense2.dinputs)\n",
    "    dense1.backward(activation1.dinputs)\n",
    "    \n",
    "    # Update weights and biases\n",
    "    optimizer.pre_update_params()\n",
    "    optimizer.update_params(dense1)\n",
    "    optimizer.update_params(dense2)\n",
    "    optimizer.post_update_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Momentum\n",
    "- momentum creates a rolling average of gradients over some number of epochs or training steps\n",
    "- helps to avoid getting stuck in local minimums because if previous gradients were very high, they will play into the current weight update, which might be small because the model is near a local minimum. So the momentum will increase the weight update preventing the model from getting stuck in the local minimum\n",
    "- kind of like a ball rolling down a hill, the steeper the hill, the bigger the hill on the other side you need to slow it down\n",
    "- in other words, the momentum helps you stay on the path of global gradient descent -looking at the greater overall average gradient - than just the gradient that is what is right next to you.\n",
    "- weight_updates_with_momentum = self.momentum * layer.weight_momentums - self.current_learning_rate * layer.dweights; where self.momentum is a momentum hyperparameter between 0 and 1 and weight momentums is an array of previous weight momentums, consisting of the previous weight updates: layer.weight_momentums = weight_updates, instantiated at 0s.\n",
    "- so basically the momentum is the previous update to the parameters, then we just incorporate new gradient info by subtracting the current gradient times the learning rate. The greater the momentum parameter, the greater the weight on the previous gradients * learning rates\n",
    "- thinking through, if momentum parameter is > 0 and the previous step was a very high gradient, then the next step is in the same direction, then the gradient update will increase. If it is in the opposite then it will decrease, but be greater than it would've been without momentum. This is where the momentum prevents the falling into local minimum. With each new step, there is greater emphasis on more recent gradient updates and the other update values are overwritten by the rolling sum, and more so if momentum param < 1. This is an exponential moving average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Update Paras function for Optimizer SGD\n",
    "- checks if momentum is not 0, if not\n",
    "- check if we have the attribute weight momentums (ie, is this the first epoch/step), and if not, then makes a gradient of 0s\n",
    "- performs the formula described above, and then sets the weight momentums to that value for the next epoch when the new weights are calculated.\n",
    "- then, updates weights like done previously "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(self, layer):\n",
    "# If we use momentum\n",
    "    if self.momentum:\n",
    "    # If layer does not contain momentum arrays, create them\n",
    "    # filled with zeros\n",
    "        if not hasattr(layer, 'weight_momentums'):\n",
    "            layer.weight_momentums = np.zeros_like(layer.weights)\n",
    "            # If there is no momentum array for weights\n",
    "            # The array doesn't exist for biases yet either.\n",
    "            layer.bias_momentums = np.zeros_like(layer.biases)\n",
    "        \n",
    "        # Build weight updates with momentum - take previous\n",
    "        # updates multiplied by retain factor and update with\n",
    "        # current gradients\n",
    "        weight_updates = self.momentum * layer.weight_momentums - self.current_learning_rate * layer.dweights\n",
    "        layer.weight_momentums = weight_updates\n",
    "        # Build bias updates\n",
    "        bias_updates = self.momentum * layer.bias_momentums - self.current_learning_rate * layer.dbiases\n",
    "        layer.bias_momentums = bias_updates\n",
    "\n",
    "    else:\n",
    "        weight_updates = -self.current_learning_rate * layer.dweights\n",
    "        bias_updates = -self.current_learning_rate * layer.dbiases\n",
    "\n",
    "    layer.weights += weight_updates\n",
    "    layer.biases += bias_updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full Optimizer With Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer_SGD:\n",
    "# Initialize optimizer - set settings,\n",
    "# learning rate of 1. is default for this optimizer\n",
    "    def __init__(self, learning_rate=1., decay=0., momentum=0.):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.momentum = momentum\n",
    "    # Call once before any parameter updates\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * (1. / (1. + self.decay*self.iterations))\n",
    "    # Update parameters\n",
    "    def update_params(self, layer):\n",
    "    # If we use momentum\n",
    "        if self.momentum:\n",
    "        # If layer does not contain momentum arrays, create them\n",
    "        # filled with zeros\n",
    "            if not hasattr(layer, 'weight_momentums'):\n",
    "                layer.weight_momentums = np.zeros_like(layer.weights)\n",
    "                # If there is no momentum array for weights\n",
    "                # The array doesn't exist for biases yet either.\n",
    "                layer.bias_momentums = np.zeros_like(layer.biases)\n",
    "            \n",
    "            # Build weight updates with momentum - take previous\n",
    "            # updates multiplied by retain factor and update with\n",
    "            # current gradients\n",
    "            weight_updates = self.momentum * layer.weight_momentums - self.current_learning_rate * layer.dweights\n",
    "            layer.weight_momentums = weight_updates\n",
    "            # Build bias updates\n",
    "            bias_updates = self.momentum * layer.bias_momentums - self.current_learning_rate * layer.dbiases\n",
    "            layer.bias_momentums = bias_updates\n",
    "\n",
    "        else:\n",
    "            weight_updates = -self.current_learning_rate * layer.dweights\n",
    "            bias_updates = -self.current_learning_rate * layer.dbiases\n",
    "\n",
    "        layer.weights += weight_updates\n",
    "        layer.biases += bias_updates\n",
    "\n",
    "    # Call once after any parameter updates\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with Momentum\n",
    "- be sure to run cell above for optimizer class with momentum AND run the last cell with the other network class\n",
    "- performance with momentum =.9 is the best we've seen so far => accuracy 93.3% and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 0.360, loss: 1.099, lr: 1.0\n",
      "epoch: 100, acc: 0.443, loss: 1.053, lr: 0.9099181073703367\n",
      "epoch: 200, acc: 0.497, loss: 0.999, lr: 0.8340283569641367\n",
      "epoch: 300, acc: 0.603, loss: 0.810, lr: 0.7698229407236336\n",
      "epoch: 400, acc: 0.700, loss: 0.700, lr: 0.7147962830593281\n",
      "epoch: 500, acc: 0.750, loss: 0.595, lr: 0.66711140760507\n",
      "epoch: 600, acc: 0.810, loss: 0.496, lr: 0.6253908692933083\n",
      "epoch: 700, acc: 0.810, loss: 0.466, lr: 0.5885815185403178\n",
      "epoch: 800, acc: 0.847, loss: 0.384, lr: 0.5558643690939411\n",
      "epoch: 900, acc: 0.850, loss: 0.364, lr: 0.526592943654555\n",
      "epoch: 1000, acc: 0.877, loss: 0.344, lr: 0.5002501250625312\n",
      "epoch: 1100, acc: 0.863, loss: 0.347, lr: 0.4764173415912339\n",
      "epoch: 1200, acc: 0.880, loss: 0.322, lr: 0.45475216007276037\n",
      "epoch: 1300, acc: 0.887, loss: 0.309, lr: 0.43497172683775553\n",
      "epoch: 1400, acc: 0.877, loss: 0.295, lr: 0.4168403501458941\n",
      "epoch: 1500, acc: 0.887, loss: 0.277, lr: 0.4001600640256102\n",
      "epoch: 1600, acc: 0.893, loss: 0.270, lr: 0.3847633705271258\n",
      "epoch: 1700, acc: 0.890, loss: 0.265, lr: 0.3705075954057058\n",
      "epoch: 1800, acc: 0.890, loss: 0.260, lr: 0.35727045373347627\n",
      "epoch: 1900, acc: 0.893, loss: 0.255, lr: 0.3449465332873405\n",
      "epoch: 2000, acc: 0.900, loss: 0.250, lr: 0.33344448149383127\n",
      "epoch: 2100, acc: 0.897, loss: 0.246, lr: 0.32268473701193934\n",
      "epoch: 2200, acc: 0.900, loss: 0.242, lr: 0.31259768677711786\n",
      "epoch: 2300, acc: 0.903, loss: 0.238, lr: 0.3031221582297666\n",
      "epoch: 2400, acc: 0.903, loss: 0.234, lr: 0.29420417769932333\n",
      "epoch: 2500, acc: 0.903, loss: 0.230, lr: 0.2857959416976279\n",
      "epoch: 2600, acc: 0.900, loss: 0.226, lr: 0.2778549597110308\n",
      "epoch: 2700, acc: 0.903, loss: 0.222, lr: 0.2703433360367667\n",
      "epoch: 2800, acc: 0.900, loss: 0.219, lr: 0.26322716504343247\n",
      "epoch: 2900, acc: 0.910, loss: 0.216, lr: 0.25647601949217746\n",
      "epoch: 3000, acc: 0.910, loss: 0.214, lr: 0.25006251562890724\n",
      "epoch: 3100, acc: 0.910, loss: 0.212, lr: 0.2439619419370578\n",
      "epoch: 3200, acc: 0.910, loss: 0.211, lr: 0.23815194093831865\n",
      "epoch: 3300, acc: 0.910, loss: 0.209, lr: 0.23261223540358225\n",
      "epoch: 3400, acc: 0.913, loss: 0.208, lr: 0.22732439190725165\n",
      "epoch: 3500, acc: 0.913, loss: 0.206, lr: 0.22227161591464767\n",
      "epoch: 3600, acc: 0.917, loss: 0.205, lr: 0.21743857360295715\n",
      "epoch: 3700, acc: 0.917, loss: 0.204, lr: 0.21281123643328367\n",
      "epoch: 3800, acc: 0.920, loss: 0.202, lr: 0.20837674515524068\n",
      "epoch: 3900, acc: 0.920, loss: 0.201, lr: 0.20412329046744235\n",
      "epoch: 4000, acc: 0.920, loss: 0.201, lr: 0.2000400080016003\n",
      "epoch: 4100, acc: 0.920, loss: 0.200, lr: 0.19611688566385566\n",
      "epoch: 4200, acc: 0.920, loss: 0.199, lr: 0.19234468166955185\n",
      "epoch: 4300, acc: 0.923, loss: 0.198, lr: 0.18871485185884126\n",
      "epoch: 4400, acc: 0.923, loss: 0.197, lr: 0.18521948508983144\n",
      "epoch: 4500, acc: 0.923, loss: 0.197, lr: 0.18185124568103292\n",
      "epoch: 4600, acc: 0.923, loss: 0.196, lr: 0.1786033220217896\n",
      "epoch: 4700, acc: 0.920, loss: 0.195, lr: 0.1754693805930865\n",
      "epoch: 4800, acc: 0.923, loss: 0.195, lr: 0.17244352474564578\n",
      "epoch: 4900, acc: 0.923, loss: 0.194, lr: 0.16952025767079165\n",
      "epoch: 5000, acc: 0.920, loss: 0.193, lr: 0.16669444907484582\n",
      "epoch: 5100, acc: 0.923, loss: 0.192, lr: 0.16396130513198884\n",
      "epoch: 5200, acc: 0.920, loss: 0.191, lr: 0.16131634134537828\n",
      "epoch: 5300, acc: 0.920, loss: 0.190, lr: 0.15875535799333226\n",
      "epoch: 5400, acc: 0.920, loss: 0.190, lr: 0.1562744178777934\n",
      "epoch: 5500, acc: 0.920, loss: 0.189, lr: 0.15386982612709646\n",
      "epoch: 5600, acc: 0.923, loss: 0.188, lr: 0.15153811183512653\n",
      "epoch: 5700, acc: 0.923, loss: 0.188, lr: 0.14927601134497687\n",
      "epoch: 5800, acc: 0.923, loss: 0.187, lr: 0.14708045300779526\n",
      "epoch: 5900, acc: 0.923, loss: 0.187, lr: 0.14494854326714016\n",
      "epoch: 6000, acc: 0.923, loss: 0.186, lr: 0.1428775539362766\n",
      "epoch: 6100, acc: 0.927, loss: 0.186, lr: 0.1408649105507818\n",
      "epoch: 6200, acc: 0.927, loss: 0.185, lr: 0.13890818169190167\n",
      "epoch: 6300, acc: 0.927, loss: 0.185, lr: 0.13700506918755992\n",
      "epoch: 6400, acc: 0.927, loss: 0.184, lr: 0.13515339910798757\n",
      "epoch: 6500, acc: 0.923, loss: 0.184, lr: 0.13335111348179757\n",
      "epoch: 6600, acc: 0.927, loss: 0.184, lr: 0.13159626266614027\n",
      "epoch: 6700, acc: 0.927, loss: 0.183, lr: 0.12988699831146902\n",
      "epoch: 6800, acc: 0.927, loss: 0.183, lr: 0.12822156686754713\n",
      "epoch: 6900, acc: 0.930, loss: 0.182, lr: 0.126598303582732\n",
      "epoch: 7000, acc: 0.927, loss: 0.182, lr: 0.12501562695336915\n",
      "epoch: 7100, acc: 0.930, loss: 0.181, lr: 0.12347203358439313\n",
      "epoch: 7200, acc: 0.930, loss: 0.181, lr: 0.12196609342602757\n",
      "epoch: 7300, acc: 0.930, loss: 0.180, lr: 0.12049644535486204\n",
      "epoch: 7400, acc: 0.933, loss: 0.180, lr: 0.11906179307060363\n",
      "epoch: 7500, acc: 0.930, loss: 0.180, lr: 0.11766090128250381\n",
      "epoch: 7600, acc: 0.933, loss: 0.179, lr: 0.11629259216187929\n",
      "epoch: 7700, acc: 0.937, loss: 0.179, lr: 0.11495574203931487\n",
      "epoch: 7800, acc: 0.930, loss: 0.179, lr: 0.11364927832708263\n",
      "epoch: 7900, acc: 0.933, loss: 0.178, lr: 0.11237217664906168\n",
      "epoch: 8000, acc: 0.933, loss: 0.178, lr: 0.11112345816201799\n",
      "epoch: 8100, acc: 0.933, loss: 0.178, lr: 0.10990218705352237\n",
      "epoch: 8200, acc: 0.930, loss: 0.177, lr: 0.10870746820306555\n",
      "epoch: 8300, acc: 0.930, loss: 0.177, lr: 0.1075384449940854\n",
      "epoch: 8400, acc: 0.933, loss: 0.177, lr: 0.10639429726566654\n",
      "epoch: 8500, acc: 0.933, loss: 0.177, lr: 0.10527423939362038\n",
      "epoch: 8600, acc: 0.933, loss: 0.176, lr: 0.10417751849150952\n",
      "epoch: 8700, acc: 0.933, loss: 0.175, lr: 0.10310341272296113\n",
      "epoch: 8800, acc: 0.933, loss: 0.175, lr: 0.1020512297173181\n",
      "epoch: 8900, acc: 0.930, loss: 0.175, lr: 0.10102030508132134\n",
      "epoch: 9000, acc: 0.933, loss: 0.175, lr: 0.1000100010001\n",
      "epoch: 9100, acc: 0.933, loss: 0.175, lr: 0.09901970492127933\n",
      "epoch: 9200, acc: 0.933, loss: 0.174, lr: 0.09804882831650162\n",
      "epoch: 9300, acc: 0.930, loss: 0.174, lr: 0.09709680551509856\n",
      "epoch: 9400, acc: 0.933, loss: 0.174, lr: 0.09616309260505818\n",
      "epoch: 9500, acc: 0.933, loss: 0.174, lr: 0.09524716639679968\n",
      "epoch: 9600, acc: 0.933, loss: 0.174, lr: 0.09434852344560807\n",
      "epoch: 9700, acc: 0.933, loss: 0.173, lr: 0.09346667912889055\n",
      "epoch: 9800, acc: 0.933, loss: 0.173, lr: 0.09260116677470137\n",
      "epoch: 9900, acc: 0.933, loss: 0.173, lr: 0.09175153683824203\n",
      "epoch: 10000, acc: 0.933, loss: 0.173, lr: 0.09091735612328393\n"
     ]
    }
   ],
   "source": [
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "import numpy as np\n",
    "nnfs.init()\n",
    "\n",
    "###NOTE: run full network code in final cell of this workbook so that this example works\n",
    "\n",
    "# Create dataset\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# Create Dense layer with 2 input features and 64 output values\n",
    "dense1 = Layer_Dense(2, 64)\n",
    "\n",
    "# Create ReLU activation (to be used with Dense layer):\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "# Create second Dense layer with 64 input features (as we take output\n",
    "# of previous layer here) and 3 output values (output values)\n",
    "dense2 = Layer_Dense(64, 3)\n",
    "\n",
    "# Create Softmax classifier's combined loss and activation\n",
    "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = Optimizer_SGD(decay=1e-3, momentum=.9)\n",
    "# Train in loop\n",
    "for epoch in range(10001):\n",
    "    # Perform a forward pass of our training data through this layer\n",
    "    dense1.forward(X)\n",
    "    \n",
    "    # Perform a forward pass through activation function\n",
    "    # takes the output of first dense layer here\n",
    "    activation1.forward(dense1.output)\n",
    "    \n",
    "    # Perform a forward pass through second Dense layer\n",
    "    # takes outputs of activation function of first layer as inputs\n",
    "    dense2.forward(activation1.output)\n",
    "    \n",
    "    # Perform a forward pass through the activation/loss function\n",
    "    # takes the output of second dense layer here and returns loss\n",
    "    loss = loss_activation.forward(dense2.output, y)\n",
    "\n",
    "    # Calculate accuracy from output of activation2 and targets\n",
    "    # calculate values along first axis\n",
    "    predictions = np.argmax(loss_activation.output, axis=1)\n",
    "    if len(y.shape) == 2:\n",
    "        y = np.argmax(y, axis=1)\n",
    "    accuracy = np.mean(predictions==y)\n",
    "    \n",
    "    if not epoch % 100: #only every hundredth epoch\n",
    "        print(f'epoch: {epoch}, ' +\n",
    "        f'acc: {accuracy:.3f}, ' +\n",
    "        f'loss: {loss:.3f}, ' +\n",
    "        f'lr: {optimizer.current_learning_rate}')\n",
    "    \n",
    "    # Backward pass\n",
    "    loss_activation.backward(loss_activation.output, y)\n",
    "    dense2.backward(loss_activation.dinputs)\n",
    "    activation1.backward(dense2.dinputs)\n",
    "    dense1.backward(activation1.dinputs)\n",
    "    \n",
    "    # Update weights and biases\n",
    "    optimizer.pre_update_params()\n",
    "    optimizer.update_params(dense1)\n",
    "    optimizer.update_params(dense2)\n",
    "    optimizer.post_update_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaGrad - Adaptive Gradient\n",
    "- Adaptive gradient institutes a per-parameter learning rate rather than a globally shared rate.\n",
    "- When do you use adagrad? When you have sparse gradients (i.e., many gradient values are 0) or variables with different sizes/magnitudes. It may also be more computationally efficient than an optimizer like adam. However, adagrad is not used as frequently as adam\n",
    "- adagrad formula: cache += parm_gradient ** 2; parm_updates = learning_rate * parm_gradient /(sqrt(cache) + eps)\n",
    "- so keep a cumulative sum of squared gradients for a parameter in the cache variable, then divide the current parameter gradient by the square root of the cache value plus epsilon\n",
    "- this has the effect of progressively lowering the gradient update amount for parameters that have very high gradients \n",
    "- epsilon is a hyperparameter preventing division by 0. Typically it is set very low, such as 1e-7\n",
    "- summing the squared values and then taking the square root causes the overall parm_gradient to be scaled more slowly -> 1 + 3 =4; sqrt(1^2 + 3^2) = 2.16\n",
    "- so basically gradient updates get progressively smaller if cache is rising. Parameters with small gradients will have learning rates decreased slower than ones with higher \n",
    "- Per questioning chatGPT, this basically assumes that frequently updated (i.e. non sparse) or large parameters have less of an impact or include less new information for a constant change in learning rate than would a smaller/sparse parameter for the same change in learning rate.\n",
    "- adagrad is prone to stalling because if the cache becomes very large, then updates will be very small\n",
    "- see below for new update params function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(self, layer):\n",
    "    # If layer does not contain cache arrays,\n",
    "    # create them filled with zeros\n",
    "    if not hasattr(layer, 'weight_cache'):\n",
    "        layer.weight_cache = np.zeros_like(layer.weights)\n",
    "        layer.bias_cache = np.zeros_like(layer.biases)\n",
    "    # Update cache with squared current gradients\n",
    "    layer.weight_cache += layer.dweights**2\n",
    "    layer.bias_cache += layer.dbiases**2\n",
    "    # Vanilla SGD parameter update + normalization\n",
    "    # with square rooted cache\n",
    "    layer.weights += -self.current_learning_rate * layer.dweights / (np.sqrt(layer.weight_cache) + self.epsilon)\n",
    "    layer.biases += -self.current_learning_rate * layer.dbiases / (np.sqrt(layer.bias_cache) + self.epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full adagrad function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer_Adagrad:\n",
    "# Initialize optimizer - set settings,\n",
    "# learning rate of 1. is default for this optimizer\n",
    "    def __init__(self, learning_rate=1., decay=0., epsilon=1e-7):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.epsilon = epsilon\n",
    "    # Call once before any parameter updates\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * (1. / (1. + self.decay*self.iterations))\n",
    "    # Update parameters\n",
    "    def update_params(self, layer):\n",
    "        # If layer does not contain cache arrays,\n",
    "        # create them filled with zeros\n",
    "        if not hasattr(layer, 'weight_cache'):\n",
    "            layer.weight_cache = np.zeros_like(layer.weights)\n",
    "            layer.bias_cache = np.zeros_like(layer.biases)\n",
    "        # Update cache with squared current gradients\n",
    "        layer.weight_cache += layer.dweights**2\n",
    "        layer.bias_cache += layer.dbiases**2\n",
    "        # Vanilla SGD parameter update + normalization\n",
    "        # with square rooted cache\n",
    "        layer.weights += -self.current_learning_rate * layer.dweights / (np.sqrt(layer.weight_cache) + self.epsilon)\n",
    "        layer.biases += -self.current_learning_rate * layer.dbiases / (np.sqrt(layer.bias_cache) + self.epsilon)\n",
    "\n",
    "    # Call once after any parameter updates\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing out Adagrad\n",
    "- note please run the cell above and the last cell in workbook when testing\n",
    "- with decay of 1e-4, this does pretty well but not as good as SGD with momentum, 1e-4 works best for learning rate decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 0.360, loss: 1.099, lr: 1.0\n",
      "epoch: 100, acc: 0.457, loss: 1.012, lr: 0.9901970492127933\n",
      "epoch: 200, acc: 0.527, loss: 0.936, lr: 0.9804882831650161\n",
      "epoch: 300, acc: 0.600, loss: 0.874, lr: 0.9709680551509855\n",
      "epoch: 400, acc: 0.623, loss: 0.830, lr: 0.9616309260505818\n",
      "epoch: 500, acc: 0.617, loss: 0.791, lr: 0.9524716639679969\n",
      "epoch: 600, acc: 0.663, loss: 0.761, lr: 0.9434852344560807\n",
      "epoch: 700, acc: 0.667, loss: 0.733, lr: 0.9346667912889054\n",
      "epoch: 800, acc: 0.680, loss: 0.704, lr: 0.9260116677470135\n",
      "epoch: 900, acc: 0.687, loss: 0.686, lr: 0.9175153683824203\n",
      "epoch: 1000, acc: 0.683, loss: 0.669, lr: 0.9091735612328392\n",
      "epoch: 1100, acc: 0.703, loss: 0.653, lr: 0.9009820704567978\n",
      "epoch: 1200, acc: 0.700, loss: 0.640, lr: 0.892936869363336\n",
      "epoch: 1300, acc: 0.717, loss: 0.629, lr: 0.8850340738118416\n",
      "epoch: 1400, acc: 0.713, loss: 0.615, lr: 0.8772699359592947\n",
      "epoch: 1500, acc: 0.727, loss: 0.601, lr: 0.8696408383337683\n",
      "epoch: 1600, acc: 0.737, loss: 0.589, lr: 0.8621432882145013\n",
      "epoch: 1700, acc: 0.750, loss: 0.579, lr: 0.8547739123001966\n",
      "epoch: 1800, acc: 0.750, loss: 0.571, lr: 0.8475294516484448\n",
      "epoch: 1900, acc: 0.750, loss: 0.562, lr: 0.8404067568703253\n",
      "epoch: 2000, acc: 0.760, loss: 0.557, lr: 0.8334027835652972\n",
      "epoch: 2100, acc: 0.757, loss: 0.548, lr: 0.8265145879824779\n",
      "epoch: 2200, acc: 0.757, loss: 0.543, lr: 0.8197393228953193\n",
      "epoch: 2300, acc: 0.763, loss: 0.537, lr: 0.8130742336775347\n",
      "epoch: 2400, acc: 0.763, loss: 0.532, lr: 0.8065166545689169\n",
      "epoch: 2500, acc: 0.763, loss: 0.527, lr: 0.8000640051204096\n",
      "epoch: 2600, acc: 0.767, loss: 0.522, lr: 0.7937137868084768\n",
      "epoch: 2700, acc: 0.773, loss: 0.519, lr: 0.7874635798094338\n",
      "epoch: 2800, acc: 0.780, loss: 0.514, lr: 0.7813110399249941\n",
      "epoch: 2900, acc: 0.780, loss: 0.510, lr: 0.7752538956508256\n",
      "epoch: 3000, acc: 0.780, loss: 0.508, lr: 0.7692899453804138\n",
      "epoch: 3100, acc: 0.777, loss: 0.503, lr: 0.7634170547370028\n",
      "epoch: 3200, acc: 0.780, loss: 0.500, lr: 0.7576331540268202\n",
      "epoch: 3300, acc: 0.780, loss: 0.497, lr: 0.7519362358072035\n",
      "epoch: 3400, acc: 0.783, loss: 0.492, lr: 0.7463243525636241\n",
      "epoch: 3500, acc: 0.780, loss: 0.490, lr: 0.7407956144899621\n",
      "epoch: 3600, acc: 0.777, loss: 0.487, lr: 0.735348187366718\n",
      "epoch: 3700, acc: 0.780, loss: 0.484, lr: 0.7299802905321557\n",
      "epoch: 3800, acc: 0.780, loss: 0.482, lr: 0.7246901949416624\n",
      "epoch: 3900, acc: 0.777, loss: 0.479, lr: 0.7194762213108857\n",
      "epoch: 4000, acc: 0.777, loss: 0.477, lr: 0.7143367383384527\n",
      "epoch: 4100, acc: 0.777, loss: 0.475, lr: 0.7092701610043266\n",
      "epoch: 4200, acc: 0.783, loss: 0.472, lr: 0.7042749489400663\n",
      "epoch: 4300, acc: 0.787, loss: 0.470, lr: 0.6993496048674733\n",
      "epoch: 4400, acc: 0.790, loss: 0.468, lr: 0.6944926731022988\n",
      "epoch: 4500, acc: 0.790, loss: 0.467, lr: 0.6897027381198704\n",
      "epoch: 4600, acc: 0.797, loss: 0.464, lr: 0.6849784231796698\n",
      "epoch: 4700, acc: 0.800, loss: 0.464, lr: 0.6803183890060548\n",
      "epoch: 4800, acc: 0.803, loss: 0.461, lr: 0.6757213325224677\n",
      "epoch: 4900, acc: 0.803, loss: 0.458, lr: 0.6711859856366199\n",
      "epoch: 5000, acc: 0.807, loss: 0.457, lr: 0.6667111140742716\n",
      "epoch: 5100, acc: 0.810, loss: 0.454, lr: 0.6622955162593549\n",
      "epoch: 5200, acc: 0.810, loss: 0.452, lr: 0.6579380222383051\n",
      "epoch: 5300, acc: 0.813, loss: 0.450, lr: 0.6536374926465782\n",
      "epoch: 5400, acc: 0.810, loss: 0.448, lr: 0.649392817715436\n",
      "epoch: 5500, acc: 0.810, loss: 0.446, lr: 0.6452029163171817\n",
      "epoch: 5600, acc: 0.810, loss: 0.445, lr: 0.6410667350471184\n",
      "epoch: 5700, acc: 0.810, loss: 0.443, lr: 0.6369832473405949\n",
      "epoch: 5800, acc: 0.810, loss: 0.441, lr: 0.6329514526235838\n",
      "epoch: 5900, acc: 0.810, loss: 0.439, lr: 0.6289703754953141\n",
      "epoch: 6000, acc: 0.813, loss: 0.437, lr: 0.6250390649415589\n",
      "epoch: 6100, acc: 0.807, loss: 0.435, lr: 0.6211565935772407\n",
      "epoch: 6200, acc: 0.810, loss: 0.433, lr: 0.6173220569170937\n",
      "epoch: 6300, acc: 0.810, loss: 0.432, lr: 0.6135345726731701\n",
      "epoch: 6400, acc: 0.810, loss: 0.431, lr: 0.6097932800780536\n",
      "epoch: 6500, acc: 0.817, loss: 0.429, lr: 0.6060973392326807\n",
      "epoch: 6600, acc: 0.817, loss: 0.427, lr: 0.6024459304777396\n",
      "epoch: 6700, acc: 0.820, loss: 0.426, lr: 0.5988382537876519\n",
      "epoch: 6800, acc: 0.820, loss: 0.424, lr: 0.5952735281862016\n",
      "epoch: 6900, acc: 0.823, loss: 0.422, lr: 0.5917509911829102\n",
      "epoch: 7000, acc: 0.820, loss: 0.421, lr: 0.5882698982293076\n",
      "epoch: 7100, acc: 0.820, loss: 0.419, lr: 0.5848295221942803\n",
      "epoch: 7200, acc: 0.820, loss: 0.418, lr: 0.5814291528577243\n",
      "epoch: 7300, acc: 0.827, loss: 0.416, lr: 0.5780680964217585\n",
      "epoch: 7400, acc: 0.827, loss: 0.415, lr: 0.5747456750387954\n",
      "epoch: 7500, acc: 0.830, loss: 0.412, lr: 0.5714612263557918\n",
      "epoch: 7600, acc: 0.830, loss: 0.412, lr: 0.5682141030740383\n",
      "epoch: 7700, acc: 0.830, loss: 0.410, lr: 0.5650036725238714\n",
      "epoch: 7800, acc: 0.827, loss: 0.408, lr: 0.5618293162537221\n",
      "epoch: 7900, acc: 0.830, loss: 0.406, lr: 0.5586904296329404\n",
      "epoch: 8000, acc: 0.833, loss: 0.405, lr: 0.5555864214678593\n",
      "epoch: 8100, acc: 0.837, loss: 0.404, lr: 0.5525167136305873\n",
      "epoch: 8200, acc: 0.833, loss: 0.403, lr: 0.5494807407000385\n",
      "epoch: 8300, acc: 0.837, loss: 0.401, lr: 0.5464779496147331\n",
      "epoch: 8400, acc: 0.837, loss: 0.399, lr: 0.5435077993369205\n",
      "epoch: 8500, acc: 0.837, loss: 0.398, lr: 0.5405697605275961\n",
      "epoch: 8600, acc: 0.837, loss: 0.396, lr: 0.5376633152320017\n",
      "epoch: 8700, acc: 0.837, loss: 0.395, lr: 0.5347879565752179\n",
      "epoch: 8800, acc: 0.837, loss: 0.394, lr: 0.5319431884674717\n",
      "epoch: 8900, acc: 0.837, loss: 0.392, lr: 0.5291285253188\n",
      "epoch: 9000, acc: 0.837, loss: 0.390, lr: 0.5263434917627243\n",
      "epoch: 9100, acc: 0.843, loss: 0.389, lr: 0.5235876223886068\n",
      "epoch: 9200, acc: 0.843, loss: 0.389, lr: 0.5208604614823689\n",
      "epoch: 9300, acc: 0.843, loss: 0.387, lr: 0.5181615627752734\n",
      "epoch: 9400, acc: 0.843, loss: 0.386, lr: 0.5154904892004742\n",
      "epoch: 9500, acc: 0.843, loss: 0.385, lr: 0.5128468126570593\n",
      "epoch: 9600, acc: 0.843, loss: 0.384, lr: 0.5102301137813153\n",
      "epoch: 9700, acc: 0.843, loss: 0.383, lr: 0.5076399817249606\n",
      "epoch: 9800, acc: 0.847, loss: 0.382, lr: 0.5050760139400979\n",
      "epoch: 9900, acc: 0.847, loss: 0.381, lr: 0.5025378159706518\n",
      "epoch: 10000, acc: 0.847, loss: 0.379, lr: 0.5000250012500626\n"
     ]
    }
   ],
   "source": [
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "import numpy as np\n",
    "nnfs.init()\n",
    "\n",
    "###NOTE: run full network code in final cell of this workbook so that this example works\n",
    "\n",
    "# Create dataset\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# Create Dense layer with 2 input features and 64 output values\n",
    "dense1 = Layer_Dense(2, 64)\n",
    "\n",
    "# Create ReLU activation (to be used with Dense layer):\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "# Create second Dense layer with 64 input features (as we take output\n",
    "# of previous layer here) and 3 output values (output values)\n",
    "dense2 = Layer_Dense(64, 3)\n",
    "\n",
    "# Create Softmax classifier's combined loss and activation\n",
    "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = Optimizer_Adagrad(decay=1e-4)\n",
    "# Train in loop\n",
    "for epoch in range(10001):\n",
    "    # Perform a forward pass of our training data through this layer\n",
    "    dense1.forward(X)\n",
    "    \n",
    "    # Perform a forward pass through activation function\n",
    "    # takes the output of first dense layer here\n",
    "    activation1.forward(dense1.output)\n",
    "    \n",
    "    # Perform a forward pass through second Dense layer\n",
    "    # takes outputs of activation function of first layer as inputs\n",
    "    dense2.forward(activation1.output)\n",
    "    \n",
    "    # Perform a forward pass through the activation/loss function\n",
    "    # takes the output of second dense layer here and returns loss\n",
    "    loss = loss_activation.forward(dense2.output, y)\n",
    "\n",
    "    # Calculate accuracy from output of activation2 and targets\n",
    "    # calculate values along first axis\n",
    "    predictions = np.argmax(loss_activation.output, axis=1)\n",
    "    if len(y.shape) == 2:\n",
    "        y = np.argmax(y, axis=1)\n",
    "    accuracy = np.mean(predictions==y)\n",
    "    \n",
    "    if not epoch % 100: #only every hundredth epoch\n",
    "        print(f'epoch: {epoch}, ' +\n",
    "        f'acc: {accuracy:.3f}, ' +\n",
    "        f'loss: {loss:.3f}, ' +\n",
    "        f'lr: {optimizer.current_learning_rate}')\n",
    "    \n",
    "    # Backward pass\n",
    "    loss_activation.backward(loss_activation.output, y)\n",
    "    dense2.backward(loss_activation.dinputs)\n",
    "    activation1.backward(dense2.dinputs)\n",
    "    dense1.backward(activation1.dinputs)\n",
    "    \n",
    "    # Update weights and biases\n",
    "    optimizer.pre_update_params()\n",
    "    optimizer.update_params(dense1)\n",
    "    optimizer.update_params(dense2)\n",
    "    optimizer.post_update_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSProp\n",
    "- similar to adagrad in that we are incorporating per-parameter learing rate, however, in this case it is done via an exponentially weighted moving average similar to how momentum is incorporated\n",
    "- RMSProp formula: cache = rho * cache + (1 - rho) * gradient ** 2; as with adagrad, use the sqrt of cache to plus epsilon to scale the gradient\n",
    "- benefits of this approach over adagrad are that the learning rate can change upwards or downwards depending on the most recent gradients, as opposed to adagrad where the cache keeps increasing with each non-zero gradient. Also, does not accumulate very old gradients and can control how much emphasis on old gradients there is via rho.\n",
    "- so get to track the global direction of descent better and makes it less prone learning stalling\n",
    "- rho parameter adjusts empasis on recent gradients vs older gradients. The higher rho is, the smaller portion each new gradient has in the cache, and the more influence older gradients have. Greater rho = greater memory of old gradients\n",
    "- need to lower learning rate as well => my guess is because a higher learning rate would result in very large gradients if somehow the cache became very low or near zero. Dividing by a very small number would create big gradient update possibly causing instability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSProp Class\n",
    "- exact same as adagrad, just changed the cache funtions and learning rate. Note that instead of just doing +=, the moving average is now setting the cache variable equal to the previous cache and current gradients weighted by rho or 1-rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer_RMSprop:\n",
    "# Initialize optimizer - set settings,\n",
    "# learning rate of 1. is default for this optimizer\n",
    "    def __init__(self, learning_rate=.001, decay=0., epsilon=1e-7, rho=.9):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.epsilon = epsilon\n",
    "        self.rho = rho\n",
    "    # Call once before any parameter updates\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * (1. / (1. + self.decay*self.iterations))\n",
    "    # Update parameters\n",
    "    def update_params(self, layer):\n",
    "        # If layer does not contain cache arrays,\n",
    "        # create them filled with zeros\n",
    "        if not hasattr(layer, 'weight_cache'):\n",
    "            layer.weight_cache = np.zeros_like(layer.weights)\n",
    "            layer.bias_cache = np.zeros_like(layer.biases)\n",
    "        # Update cache with squared current gradients\n",
    "        layer.weight_cache = self.rho * layer.weight_cache + (1 - self.rho) * layer.dweights**2\n",
    "        layer.bias_cache = self.rho * layer.bias_cache + (1 - self.rho) * layer.dbiases**2\n",
    "        # Vanilla SGD parameter update + normalization\n",
    "        # with square rooted cache\n",
    "        layer.weights += -self.current_learning_rate * layer.dweights / (np.sqrt(layer.weight_cache) + self.epsilon)\n",
    "        layer.biases += -self.current_learning_rate * layer.dbiases / (np.sqrt(layer.bias_cache) + self.epsilon)\n",
    "\n",
    "    # Call once after any parameter updates\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing out RMSProp\n",
    "- note please run the cell above and the last cell in workbook when testing\n",
    "- still not as good as SGD with momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 0.360, loss: 1.099, lr: 0.02\n",
      "epoch: 100, acc: 0.467, loss: 1.014, lr: 0.01998021958261321\n",
      "epoch: 200, acc: 0.530, loss: 0.959, lr: 0.019960279044701046\n",
      "epoch: 300, acc: 0.563, loss: 0.891, lr: 0.019940378268975763\n",
      "epoch: 400, acc: 0.587, loss: 0.839, lr: 0.01992051713662487\n",
      "epoch: 500, acc: 0.593, loss: 0.805, lr: 0.01990069552930875\n",
      "epoch: 600, acc: 0.623, loss: 0.762, lr: 0.019880913329158343\n",
      "epoch: 700, acc: 0.653, loss: 0.750, lr: 0.019861170418772778\n",
      "epoch: 800, acc: 0.597, loss: 0.897, lr: 0.019841466681217078\n",
      "epoch: 900, acc: 0.670, loss: 0.736, lr: 0.01982180200001982\n",
      "epoch: 1000, acc: 0.710, loss: 0.634, lr: 0.019802176259170884\n",
      "epoch: 1100, acc: 0.767, loss: 0.612, lr: 0.01978258934311912\n",
      "epoch: 1200, acc: 0.760, loss: 0.566, lr: 0.01976304113677013\n",
      "epoch: 1300, acc: 0.733, loss: 0.607, lr: 0.019743531525483964\n",
      "epoch: 1400, acc: 0.777, loss: 0.537, lr: 0.01972406039507293\n",
      "epoch: 1500, acc: 0.797, loss: 0.528, lr: 0.019704627631799327\n",
      "epoch: 1600, acc: 0.777, loss: 0.544, lr: 0.019685233122373254\n",
      "epoch: 1700, acc: 0.780, loss: 0.498, lr: 0.019665876753950384\n",
      "epoch: 1800, acc: 0.810, loss: 0.475, lr: 0.01964655841412981\n",
      "epoch: 1900, acc: 0.817, loss: 0.473, lr: 0.019627277990951823\n",
      "epoch: 2000, acc: 0.797, loss: 0.469, lr: 0.019608035372895814\n",
      "epoch: 2100, acc: 0.773, loss: 0.468, lr: 0.01958883044887805\n",
      "epoch: 2200, acc: 0.793, loss: 0.450, lr: 0.019569663108249594\n",
      "epoch: 2300, acc: 0.817, loss: 0.434, lr: 0.01955053324079414\n",
      "epoch: 2400, acc: 0.823, loss: 0.407, lr: 0.019531440736725945\n",
      "epoch: 2500, acc: 0.827, loss: 0.414, lr: 0.019512385486687673\n",
      "epoch: 2600, acc: 0.830, loss: 0.412, lr: 0.019493367381748363\n",
      "epoch: 2700, acc: 0.813, loss: 0.395, lr: 0.019474386313401298\n",
      "epoch: 2800, acc: 0.823, loss: 0.400, lr: 0.019455442173562\n",
      "epoch: 2900, acc: 0.830, loss: 0.393, lr: 0.019436534854566128\n",
      "epoch: 3000, acc: 0.563, loss: 1.322, lr: 0.01941766424916747\n",
      "epoch: 3100, acc: 0.837, loss: 0.379, lr: 0.019398830250535893\n",
      "epoch: 3200, acc: 0.843, loss: 0.378, lr: 0.019380032752255354\n",
      "epoch: 3300, acc: 0.843, loss: 0.374, lr: 0.01936127164832186\n",
      "epoch: 3400, acc: 0.833, loss: 0.366, lr: 0.01934254683314152\n",
      "epoch: 3500, acc: 0.830, loss: 0.367, lr: 0.019323858201528515\n",
      "epoch: 3600, acc: 0.843, loss: 0.342, lr: 0.019305205648703173\n",
      "epoch: 3700, acc: 0.847, loss: 0.351, lr: 0.01928658907028997\n",
      "epoch: 3800, acc: 0.850, loss: 0.351, lr: 0.01926800836231563\n",
      "epoch: 3900, acc: 0.853, loss: 0.347, lr: 0.019249463421207133\n",
      "epoch: 4000, acc: 0.770, loss: 0.517, lr: 0.019230954143789846\n",
      "epoch: 4100, acc: 0.847, loss: 0.328, lr: 0.019212480427285565\n",
      "epoch: 4200, acc: 0.850, loss: 0.331, lr: 0.019194042169310647\n",
      "epoch: 4300, acc: 0.853, loss: 0.331, lr: 0.019175639267874092\n",
      "epoch: 4400, acc: 0.857, loss: 0.329, lr: 0.019157271621375684\n",
      "epoch: 4500, acc: 0.857, loss: 0.344, lr: 0.0191389391286041\n",
      "epoch: 4600, acc: 0.847, loss: 0.324, lr: 0.019120641688735073\n",
      "epoch: 4700, acc: 0.850, loss: 0.324, lr: 0.019102379201329525\n",
      "epoch: 4800, acc: 0.870, loss: 0.298, lr: 0.01908415156633174\n",
      "epoch: 4900, acc: 0.860, loss: 0.306, lr: 0.01906595868406753\n",
      "epoch: 5000, acc: 0.860, loss: 0.311, lr: 0.01904780045524243\n",
      "epoch: 5100, acc: 0.857, loss: 0.312, lr: 0.019029676780939874\n",
      "epoch: 5200, acc: 0.857, loss: 0.311, lr: 0.019011587562619416\n",
      "epoch: 5300, acc: 0.857, loss: 0.307, lr: 0.01899353270211493\n",
      "epoch: 5400, acc: 0.887, loss: 0.300, lr: 0.018975512101632844\n",
      "epoch: 5500, acc: 0.887, loss: 0.301, lr: 0.018957525663750367\n",
      "epoch: 5600, acc: 0.883, loss: 0.300, lr: 0.018939573291413745\n",
      "epoch: 5700, acc: 0.887, loss: 0.277, lr: 0.018921654887936498\n",
      "epoch: 5800, acc: 0.890, loss: 0.285, lr: 0.018903770356997706\n",
      "epoch: 5900, acc: 0.890, loss: 0.291, lr: 0.018885919602640248\n",
      "epoch: 6000, acc: 0.887, loss: 0.289, lr: 0.018868102529269144\n",
      "epoch: 6100, acc: 0.893, loss: 0.290, lr: 0.018850319041649778\n",
      "epoch: 6200, acc: 0.870, loss: 0.286, lr: 0.018832569044906263\n",
      "epoch: 6300, acc: 0.873, loss: 0.287, lr: 0.018814852444519702\n",
      "epoch: 6400, acc: 0.877, loss: 0.287, lr: 0.018797169146326564\n",
      "epoch: 6500, acc: 0.887, loss: 0.270, lr: 0.01877951905651696\n",
      "epoch: 6600, acc: 0.903, loss: 0.262, lr: 0.018761902081633034\n",
      "epoch: 6700, acc: 0.893, loss: 0.267, lr: 0.018744318128567278\n",
      "epoch: 6800, acc: 0.897, loss: 0.274, lr: 0.018726767104560903\n",
      "epoch: 6900, acc: 0.897, loss: 0.275, lr: 0.018709248917202218\n",
      "epoch: 7000, acc: 0.897, loss: 0.275, lr: 0.018691763474424996\n",
      "epoch: 7100, acc: 0.900, loss: 0.274, lr: 0.018674310684506857\n",
      "epoch: 7200, acc: 0.900, loss: 0.273, lr: 0.01865689045606769\n",
      "epoch: 7300, acc: 0.873, loss: 0.266, lr: 0.01863950269806802\n",
      "epoch: 7400, acc: 0.873, loss: 0.271, lr: 0.018622147319807447\n",
      "epoch: 7500, acc: 0.880, loss: 0.270, lr: 0.018604824230923075\n",
      "epoch: 7600, acc: 0.880, loss: 0.269, lr: 0.01858753334138793\n",
      "epoch: 7700, acc: 0.877, loss: 0.267, lr: 0.018570274561509396\n",
      "epoch: 7800, acc: 0.877, loss: 0.268, lr: 0.018553047801927663\n",
      "epoch: 7900, acc: 0.910, loss: 0.245, lr: 0.018535852973614212\n",
      "epoch: 8000, acc: 0.903, loss: 0.253, lr: 0.01851868998787026\n",
      "epoch: 8100, acc: 0.903, loss: 0.255, lr: 0.018501558756325222\n",
      "epoch: 8200, acc: 0.903, loss: 0.254, lr: 0.01848445919093522\n",
      "epoch: 8300, acc: 0.873, loss: 0.353, lr: 0.018467391203981567\n",
      "epoch: 8400, acc: 0.897, loss: 0.239, lr: 0.018450354708069265\n",
      "epoch: 8500, acc: 0.890, loss: 0.248, lr: 0.018433349616125496\n",
      "epoch: 8600, acc: 0.887, loss: 0.251, lr: 0.018416375841398172\n",
      "epoch: 8700, acc: 0.887, loss: 0.251, lr: 0.01839943329745444\n",
      "epoch: 8800, acc: 0.887, loss: 0.252, lr: 0.01838252189817921\n",
      "epoch: 8900, acc: 0.887, loss: 0.250, lr: 0.018365641557773718\n",
      "epoch: 9000, acc: 0.900, loss: 0.220, lr: 0.018348792190754044\n",
      "epoch: 9100, acc: 0.900, loss: 0.238, lr: 0.0183319737119497\n",
      "epoch: 9200, acc: 0.890, loss: 0.242, lr: 0.018315186036502167\n",
      "epoch: 9300, acc: 0.890, loss: 0.244, lr: 0.018298429079863496\n",
      "epoch: 9400, acc: 0.890, loss: 0.245, lr: 0.018281702757794862\n",
      "epoch: 9500, acc: 0.890, loss: 0.244, lr: 0.018265006986365174\n",
      "epoch: 9600, acc: 0.893, loss: 0.241, lr: 0.018248341681949654\n",
      "epoch: 9700, acc: 0.743, loss: 0.794, lr: 0.018231706761228456\n",
      "epoch: 9800, acc: 0.917, loss: 0.213, lr: 0.018215102141185255\n",
      "epoch: 9900, acc: 0.907, loss: 0.225, lr: 0.018198527739105907\n",
      "epoch: 10000, acc: 0.910, loss: 0.221, lr: 0.018181983472577025\n"
     ]
    }
   ],
   "source": [
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "import numpy as np\n",
    "nnfs.init()\n",
    "\n",
    "###NOTE: run full network code in final cell of this workbook so that this example works\n",
    "\n",
    "# Create dataset\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# Create Dense layer with 2 input features and 64 output values\n",
    "dense1 = Layer_Dense(2, 64)\n",
    "\n",
    "# Create ReLU activation (to be used with Dense layer):\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "# Create second Dense layer with 64 input features (as we take output\n",
    "# of previous layer here) and 3 output values (output values)\n",
    "dense2 = Layer_Dense(64, 3)\n",
    "\n",
    "# Create Softmax classifier's combined loss and activation\n",
    "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = Optimizer_RMSprop(learning_rate=0.02, decay=1e-5, rho=0.999)\n",
    "# Train in loop\n",
    "for epoch in range(10001):\n",
    "    # Perform a forward pass of our training data through this layer\n",
    "    dense1.forward(X)\n",
    "    \n",
    "    # Perform a forward pass through activation function\n",
    "    # takes the output of first dense layer here\n",
    "    activation1.forward(dense1.output)\n",
    "    \n",
    "    # Perform a forward pass through second Dense layer\n",
    "    # takes outputs of activation function of first layer as inputs\n",
    "    dense2.forward(activation1.output)\n",
    "    \n",
    "    # Perform a forward pass through the activation/loss function\n",
    "    # takes the output of second dense layer here and returns loss\n",
    "    loss = loss_activation.forward(dense2.output, y)\n",
    "\n",
    "    # Calculate accuracy from output of activation2 and targets\n",
    "    # calculate values along first axis\n",
    "    predictions = np.argmax(loss_activation.output, axis=1)\n",
    "    if len(y.shape) == 2:\n",
    "        y = np.argmax(y, axis=1)\n",
    "    accuracy = np.mean(predictions==y)\n",
    "    \n",
    "    if not epoch % 100: #only every hundredth epoch\n",
    "        print(f'epoch: {epoch}, ' +\n",
    "        f'acc: {accuracy:.3f}, ' +\n",
    "        f'loss: {loss:.3f}, ' +\n",
    "        f'lr: {optimizer.current_learning_rate}')\n",
    "    \n",
    "    # Backward pass\n",
    "    loss_activation.backward(loss_activation.output, y)\n",
    "    dense2.backward(loss_activation.dinputs)\n",
    "    activation1.backward(dense2.dinputs)\n",
    "    dense1.backward(activation1.dinputs)\n",
    "    \n",
    "    # Update weights and biases\n",
    "    optimizer.pre_update_params()\n",
    "    optimizer.update_params(dense1)\n",
    "    optimizer.update_params(dense2)\n",
    "    optimizer.post_update_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam Optimizer\n",
    "- is RMSprop with momentums added back in\n",
    "- before getting in to adam fully, a few key points and insights missed on the optimizers from above: \n",
    "1) the momentum is the exponentially weighted average of the gradients, also called first moment - so we are using momentum to tell us the average direction of the gradients. It helps smooth out the noise in the gradients and get us out of local minimums\n",
    "2) the cache is the exponentially weighted uncenterd variance of the gradients, also called the second moment - (i.e. we are taking the squared deviation - not subtracting anything because assuming mean is 0, and not dividing because don't divide in EWMA). A note on uncentered variance - i feel like it is assuming the mean of the gradient is 0, but chatgpt is adament this is not an assumption in the context of Adam. Anyway, dividing by the sqrt of the cache causes gradients with higher variance to take smaller steps, and those with lower variance to take larger steps. High variance indicates an unsmooth and potentially unstable gradien, so smaller steps should be taken to not overshoot the minimum. Conversely, small variance indicates a smooth gradient and can proceed more confidently with larger steps, speeding up convergence.\n",
    "3) the momentum cache is initialzed as zeros, see RMS prop code or adam code below. This is done because it is a simple, \"neutral\" way to get a starting value for the mean gradients, again has assuming 0 all over it, at least assuming 0 to start. However, the true means of the gradients may be different. So when we begin to calculate EWMA, it will be biased towards 0 because of the 0 intialization.\n",
    "4) since we use a 0 intialized momentums and cache, we have this bias towards 0 in early steps of training because there is not enough info present to estimate a true mean, which may slow down convergence or cause instability in optimization.\n",
    "\n",
    "- So now adam - in our implementation, we include the momentum and adaptive learning rate (scaling by the sqrt of second moment see #2 above) to help with the learing process, and we also attempt to correct the 0 bias. We use two hyperparameters to do this: Beta1 and Beta2, using the weights formula as example\n",
    "1) Momentum - Uses Beta1. self.beta_1 * layer.weight_momentums + (1 - self.beta_1) * layer.dweights. So beta1 is the weight placed on the historical gradients, and 1-beta1 is the weight on current gradient\n",
    "2) Uncentered Variance - Uses Beta2. layer.weight_cache = self.beta_2 * layer.weight_cache + (1 - self.beta_2) * layer.dweights**2. So beta2 is how much empahsis on historical variance factors s 1- beta2 for current variance\n",
    "3) To adjust the means and variances upward, we divide them by 1 - beta (their respective betas), so adjusted momentum = momentum / (1 - beta1); adjusted variance = variance / (1 - beta2). Why do we use the same parameter? If you work out the math: EWMAt = EWMAt-1 * Beta + (1 - Beta) * Current Weights, so Current Weights = (EWMAt - EWMAt-1)/(1-Beta). So basically we divide by 1 - Beta because [Finish investigating this!]\n",
    "4) point about beta approaching 0 with each step to progressively remove normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full Network Code from Ch. 9 So We can make use of it for examples above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "nnfs.init()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dense layer\n",
    "class Layer_Dense:\n",
    "    # Layer initialization\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        # Initialize weights and biases\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "        # Calculate output values from input ones, weights and biases\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "        # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Gradients on parameters\n",
    "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
    "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
    "        # Gradient on values\n",
    "        self.dinputs = np.dot(dvalues, self.weights.T)\n",
    "\n",
    "# ReLU activation\n",
    "class Activation_ReLU:\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        # Calculate output values from inputs\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "    def backward(self, dvalues):\n",
    "        # Since we need to modify original variable,\n",
    "        # let’s make a copy of values first\n",
    "        self.dinputs = dvalues.copy()\n",
    "        # Zero gradient where input values were negative\n",
    "        self.dinputs[self.inputs <= 0] = 0\n",
    "\n",
    "# Softmax activation\n",
    "class Activation_Softmax:\n",
    "# Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "        \n",
    "        # Get unnormalized probabilities\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "        \n",
    "        # Normalize them for each sample\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "        \n",
    "        self.output = probabilities\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Create uninitialized array\n",
    "        self.dinputs = np.empty_like(dvalues)\n",
    "        # Enumerate outputs and gradients\n",
    "        for index, (single_output, single_dvalues) in enumerate(zip(self.output, dvalues)):\n",
    "            # Flatten output array\n",
    "            single_output = single_output.reshape(-1, 1)\n",
    "            # Calculate Jacobian matrix of the output\n",
    "            jacobian_matrix = np.diagflat(single_output) - np.dot(single_output, single_output.T)\n",
    "            # Calculate sample-wise gradient\n",
    "            # and add it to the array of sample gradients\n",
    "            self.dinputs[index] = np.dot(jacobian_matrix, single_dvalues)\n",
    "\n",
    "# Common loss class\n",
    "class Loss:\n",
    "    # Calculates the data and regularization losses\n",
    "    # given model output and ground truth values\n",
    "    def calculate(self, output, y):\n",
    "        \n",
    "        # Calculate sample losses\n",
    "        sample_losses = self.forward(output, y)\n",
    "        \n",
    "        # Calculate mean loss\n",
    "        data_loss = np.mean(sample_losses)\n",
    "        \n",
    "        # Return loss\n",
    "        return data_loss\n",
    "    \n",
    "class Loss_CategoricalCrossentropy(Loss):\n",
    "# Forward pass\n",
    "    def forward(self, y_pred, y_true):\n",
    "    # Number of samples in a batch\n",
    "        samples = len(y_pred)\n",
    "        \n",
    "        # Clip data to prevent division by 0\n",
    "        # Clip both sides to not drag mean towards any value\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "        # Probabilities for target values -\n",
    "        # only if categorical labels\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[range(samples),y_true]\n",
    "        # Mask values - only for one-hot encoded labels\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum(y_pred_clipped * y_true, axis=1)\n",
    "        # Losses\n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "        return negative_log_likelihoods\n",
    "    \n",
    "    def backward(self, dvalues, y_true):\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "        # Number of labels in every sample\n",
    "        # We'll use the first sample to count them\n",
    "        labels = len(dvalues[0])\n",
    "        # If labels are sparse, turn them into one-hot vector\n",
    "        if len(y_true.shape) == 1:\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "        \n",
    "        # Calculate gradient\n",
    "        self.dinputs = -y_true / dvalues\n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples\n",
    "\n",
    "\n",
    "class Activation_Softmax_Loss_CategoricalCrossentropy():\n",
    "# Creates activation and loss function objects\n",
    "    def __init__(self):\n",
    "        self.activation = Activation_Softmax()\n",
    "        self.loss = Loss_CategoricalCrossentropy()\n",
    "        # Forward pass\n",
    "    def forward(self, inputs, y_true):\n",
    "        # Output layer's activation function\n",
    "        self.activation.forward(inputs)\n",
    "        # Set the output\n",
    "        self.output = self.activation.output\n",
    "        # Calculate and return loss value\n",
    "        return self.loss.calculate(self.output, y_true)\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "\n",
    "        # If labels are one-hot encoded,\n",
    "        # turn them into discrete values\n",
    "        if len(y_true.shape) == 2:\n",
    "            y_true = np.argmax(y_true, axis=1)\n",
    "        \n",
    "        # Copy so we can safely modify\n",
    "        self.dinputs = dvalues.copy()\n",
    "    \n",
    "        # For each row in dinputs, get what the network has for the correct class and subtract 1\n",
    "        self.dinputs[range(samples), y_true] -= 1\n",
    "        \n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
