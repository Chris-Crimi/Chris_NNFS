{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradients, Partial Derivatives, and the Chain Rule\n",
    "-  need to calculate the derivates of the whole model including loss function with respect to each parameter (e.g., weight/bias, input)\n",
    "- need to make use of the chain rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Partial Derivative\n",
    "- firstly, taking the partial derivative of the network function with respect to each input\n",
    "- the derivative with respect to one input is one equation\n",
    "- full function's derivatives consists of a set of equations called the gradient; it is a vector of the size of the inputs containing partial derivative solutions with respect to each of the inputs\n",
    "- finding the impact of an input on output while treating all other inputs as constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Partial Derivative of a Sum\n",
    "- exactly like normal derivative: sum of derivatives is derivative of sum. \n",
    "- treat all variables as constants except the variabile of interest (i.e., the variable which we are respecting in the derivative)\n",
    "- Example: 2x + 3y^2 => derivative with respect to x is 2 because the y term drops out since it is constant, just left taking derivative of 2x. Alternatively: Derivative with respect to y is 6y because 2x is constant and then just left taking derivative of y term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Partial Derivative of Multiplication\n",
    "- noting really new => treat the constant variables as constants/coefficients. Intuition is that we are only interested in the impact of the change in the respected variable, so if y*x, d wrt. x is y, numerically, changing x by 1 will result in change of y, so y is the slope of the partial derivative, when holding y constant\n",
    "- Example: d wrt. x of 3x^3*z - y^2 + 5z + 2yz = 9x^2*z; rest of terms drop out since they are constants. z in the x term remains because it is part of coefficient here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Partial Derivative of Max\n",
    "- only taking the derivative wrt. x \n",
    "- break the function into two pieces for this, one where x < 0 & x > 0. Where x > 0, f(x) = x, so f'(x) = 1; when x < 0, f(x) = 0 , so f'(x) = 0.\n",
    "- thus derivative of max wrt. x is 1 where (x > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gradient\n",
    "- gradient is a vector composed of all of the partial derivatives of an input function, where each partial derivatie is with respect to each input variable\n",
    "- example: f(x, y, z) = 3x^3*z - y^2 + 5z + 2yz; gradient = [dx, dy, dz] = [9x^2z, -2y + 2z, 3x^3 + 5 + 2y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
