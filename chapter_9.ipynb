{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back Propagation\n",
    "- beginning with an simple example where we just seek to minimize the output of a single neuron\n",
    "- goal is to figure out how much each input, weight, and bias impacts the neuron function (and eventually then network)\n",
    "- to do this need to use the chain rule and take the derivative with respect to each input, weight, bias (only 1 bias here)\n",
    "- only use derivative with respect to weights and biases to minimize loss, but need to know derivatives with respect to inputs as well because it is used to chain to another layer (more understanding in next bullet point)\n",
    "- we are chaining the layers together via the input derivative so like derivative of each layer with respect to its input, but then on the last layer or the layer we are interested in calculating the derivative for, take the derivative of that layer with respect to weight or bias. Cause the change in the weight or bias ultimately is the ultimate input to that next layer, so it will transform that layer's input. dfunction/dweight = dlayer2(layer1output)/dlayer1 * dlayer1/dx; so its really the same thing as the chain rule, and as part of the chain rule, need to know the derivative of the outer function wih respect to its input, which is the inner function, then can take the derivative of inner function with respect to whatever parameter you want, in this case weight or bias. So the input is acting as the chain (the chain rule!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back Prop on 1 Neuron\n",
    "- Example Neuron function where x0, w0 are inputs and respective weight, b is bias: y = relu(w0 * x0 + w1 * x1 + w2 *x2 + b) = max(w0 * x0 + w1 * x1 + w2 *x2 + b, 0)\n",
    "- can be broken down even further into considering each weight* input is own function; the book does this. See function, were sum() is the sum of the weights* inputs and bias, and mul() is weights* inputs. So derivative of full neuron with respect to x0 would be deriv from next layer wrt input * dReLU()/dsum() * dsum()/dmul() * dmul()/dx0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Layer times Relu: 1.0\n",
      "Next Layer, RelU, and sum: 1.0 1.0 1.0 1.0\n",
      "Full wrt inputs, weights: -3.0 1.0 -1.0 -2.0 2.0 3.0\n"
     ]
    }
   ],
   "source": [
    "# Forward pass\n",
    "x = [1.0, -2.0, 3.0] # input values\n",
    "w = [-3.0, -1.0, 2.0] # weights\n",
    "b = 1.0 # bias\n",
    "# Multiplying inputs by weights\n",
    "xw0 = x[0] * w[0]\n",
    "xw1 = x[1] * w[1]\n",
    "xw2 = x[2] * w[2]\n",
    "# Adding weighted inputs and a bias\n",
    "z = xw0 + xw1 + xw2 + b\n",
    "# ReLU activation function\n",
    "y = max(z, 0)\n",
    "# Backward pass\n",
    "# The derivative from the next layer\n",
    "dvalue = 1.0\n",
    "\n",
    "''' Example of how this comes together\n",
    "dtwoneurons/dx0 = dnext_layer/dReLU * dReLu/dsum() * dsum()/dmul() * dmul/dx0\n",
    "'''\n",
    "\n",
    "# Derivative of ReLU and the chain rule\n",
    "drelu_dz = dvalue * (1. if z > 0 else 0.)\n",
    "print(\"Next Layer times Relu:\", drelu_dz)\n",
    "\n",
    "# Partial derivatives of the multiplication, the chain rule, deriv of plain sum is just 1 (think about it)\n",
    "dsum_dxw0 = 1\n",
    "dsum_dxw1 = 1\n",
    "dsum_dxw2 = 1\n",
    "dsum_db = 1\n",
    "drelu_dxw0 = drelu_dz * dsum_dxw0\n",
    "drelu_dxw1 = drelu_dz * dsum_dxw1\n",
    "drelu_dxw2 = drelu_dz * dsum_dxw2\n",
    "drelu_db = drelu_dz * dsum_db\n",
    "print(\"Next Layer, RelU, and sum for each sum and bias:\", drelu_dxw0, drelu_dxw1, drelu_dxw2, drelu_db)\n",
    "# Partial derivatives of the multiplication, the chain rule\n",
    "#short cut to derivative here is that the deriv wrt to weight is just input value and wrt to input is just the weight (flip-flop)\n",
    "dmul_dx0 = w[0] \n",
    "dmul_dx1 = w[1]\n",
    "dmul_dx2 = w[2]\n",
    "dmul_dw0 = x[0]\n",
    "dmul_dw1 = x[1]\n",
    "dmul_dw2 = x[2]\n",
    "drelu_dx0 = drelu_dxw0 * dmul_dx0\n",
    "drelu_dw0 = drelu_dxw0 * dmul_dw0\n",
    "drelu_dx1 = drelu_dxw1 * dmul_dx1\n",
    "drelu_dw1 = drelu_dxw1 * dmul_dw1\n",
    "drelu_dx2 = drelu_dxw2 * dmul_dx2\n",
    "drelu_dw2 = drelu_dxw2 * dmul_dw2\n",
    "\n",
    "#note that the full deriv wrt to bias is calculated above it is 1, since it is just a sum onto the sum function\n",
    "print(\"Full wrt inputs, weights:\",drelu_dx0, drelu_dw0, drelu_dx1, drelu_dw1, drelu_dx2, drelu_dw2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately Simplifying the Code Above\n",
    "- taking out all multplying by 1 etc. just leaves you with derivative of next_layer * ReLu * w0 (or x0, bias, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Layer times Relu: 1.0\n",
      "Full wrt inputs, weights: -3.0 1.0 -1.0 -2.0 2.0 3.0\n",
      "wrt bias 1.0\n"
     ]
    }
   ],
   "source": [
    "# Forward pass\n",
    "x = [1.0, -2.0, 3.0] # input values\n",
    "w = [-3.0, -1.0, 2.0] # weights\n",
    "b = 1.0 # bias\n",
    "# Multiplying inputs by weights\n",
    "xw0 = x[0] * w[0]\n",
    "xw1 = x[1] * w[1]\n",
    "xw2 = x[2] * w[2]\n",
    "# Adding weighted inputs and a bias\n",
    "z = xw0 + xw1 + xw2 + b\n",
    "# ReLU activation function\n",
    "y = max(z, 0)\n",
    "# Backward pass\n",
    "# The derivative from the next layer\n",
    "dvalue = 1.0\n",
    "\n",
    "''' Example of how this comes together\n",
    "dtwoneurons/dx0 = dnext_layer/dReLU * dReLu/dsum() * dsum()/dmul() * dmul/dx0\n",
    "\n",
    "z = sum() + b\n",
    "\n",
    "now simplified to dnext_layer/dReLU * dReLu/dz * dz/dx[0]\n",
    "'''\n",
    "\n",
    "# Derivative of ReLU and the chain rule\n",
    "drelu_dz = dvalue * (1. if z > 0 else 0.)\n",
    "print(\"Next Layer times Relu:\", drelu_dz)\n",
    "\n",
    "# Partial derivatives of the multiplication, the chain rule\n",
    "#short cut to derivative here is that the deriv wrt to weight is just input value and wrt to input is just the weight (flip-flop)\n",
    "\n",
    "drelu_dx0 = dvalue * (1. if z > 0 else 0.) * w[0]\n",
    "drelu_dw0 = dvalue * (1. if z > 0 else 0.) * x[0]\n",
    "drelu_dx1 = dvalue * (1. if z > 0 else 0.) * w[1]\n",
    "drelu_dw1 = dvalue * (1. if z > 0 else 0.) * x[1]\n",
    "drelu_dx2 = dvalue * (1. if z > 0 else 0.) * w[2]\n",
    "drelu_dw2 = dvalue * (1. if z > 0 else 0.) * x[2]\n",
    "drelu_db = dvalue * (1. if z > 0 else 0.) * 1\n",
    "print(\"Full wrt inputs, weights:\",drelu_dx0, drelu_dw0, drelu_dx1, drelu_dw1, drelu_dx2, drelu_dw2)\n",
    "print(\"wrt bias\", drelu_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decreasing the output of neuron (manually); run cell above for gradient values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Weights [-3.0, -1.0, 2.0] 1.0\n",
      "New weights [-3.001, -0.998, 1.997] 0.999\n",
      "New Output 5.985 Old Output 6\n"
     ]
    }
   ],
   "source": [
    "dx = [drelu_dx0, drelu_dx1, drelu_dx2] # gradients on inputs\n",
    "dw = [drelu_dw0, drelu_dw1, drelu_dw2] # gradients on weights\n",
    "db = drelu_db # gradient on bias...just 1 bias here\n",
    "\n",
    "#current weights and bias\n",
    "print(\"Current Weights\", w, b)\n",
    "\n",
    "#applying a small negative value to our gradient to respect to weight, ie. how much the final output changes wrt to change in weights\n",
    "#negative because we want to decrease the output of neuron\n",
    "w[0] += -0.001 * dw[0]\n",
    "w[1] += -0.001 * dw[1]\n",
    "w[2] += -0.001 * dw[2]\n",
    "b += -0.001 * db\n",
    "\n",
    "#new weight and bias\n",
    "print(\"New weights\", w, b)\n",
    "\n",
    "# Multiplying inputs by new weights\n",
    "xw0 = x[0] * w[0]\n",
    "xw1 = x[1] * w[1]\n",
    "xw2 = x[2] * w[2]\n",
    "\n",
    "# Adding\n",
    "z = xw0 + xw1 + xw2 + b\n",
    "# ReLU activation function\n",
    "y = max(z, 0)\n",
    "print(\"New Output\", y, \"Old Output\", 6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So basically gradient descent is this, which much of this insight came from reading outside the book:\n",
    "- find how much each weight impacts the loss/target function (derivative wrt weight aka gradient)\n",
    "- multiply that impact by a small constant amount across impacts (gradients) => so weights that have larger gradients will result in larger values, smaller gradients will result in smaller values (e.g., .001 * 1 < .001 * 2)\n",
    "- subtract that amount from the current weight value. Subtract because we are trying to minimize. Weights with larger impacts on function output (e.g., larger gradient) will decrease by more whereas ones with smaller gradients will decrease less\n",
    "- In other words: you are changing the weights that have the most impact by more than less impactful ones, thus \"moving in the steepest direction\" (as all the blogs say) because are changing the most impactful parameters by greater values. Adding/Subtracting a slope times some constant back to the slope so the steeper the slope (bigger gradient), the greater value you are adding/subtracting back to the slope(gradient), changing the slope by more than if it was less steep.\n",
    "- as the gradients decrease, then you make overall smaller changes to weights, so effectively taking smaller steps, the closer you get to optimizing the function at the minimum (gradients approaching zero)\n",
    "- changing the weights while holding input constant => by doing the above to change the most impactful weights by more to more quickly reduce the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was the basic process of minimizing the output of a neuron, in reality want to minimize the loss of a network. The next layer aspect of this is kind of ingnored (it is 1), although if you include the next layer wouldn't we really be minimizing the value of the next layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prelim notes from skimming - fill out further later\n",
    "\n",
    "Backpropagation Between Layers\n",
    "- so in a layer, each nueron outputs a gradient with respect to each input\n",
    "- the sum of the gradients for each respective input is the full derivative for that input. This leverages the principle that derivatives sum linearly. So partial derivative for input 1 across 3 neurons can sum togther for full derivative of input 1 for the whole layer => gained this insight thru additional reading outside the book\n",
    "- So here can just sum weights of each neuron that correspond to each respective input (excluding any other chain rule stuff from previous layer, otherwise need to multiply these first per chain rule) => this is the the shortcut approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.2   0.5  -0.26]\n",
      " [ 0.8  -0.91 -0.27]\n",
      " [-0.5   0.26  0.17]\n",
      " [ 1.   -0.5   0.87]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "weights = np.array([[0.2, 0.8, -0.5, 1],\n",
    "                    [0.5, -0.91, 0.26, -0.5],\n",
    "                    [-0.26, -0.27, 0.17, 0.87]]).T\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
