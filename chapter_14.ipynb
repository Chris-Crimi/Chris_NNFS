{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L1 and L2 Regularization\n",
    "- the goal of regularization is to prevent weights and biases from becoming too high by penalizing large weights and biases. A very high weight indicates a neuron may be trying to memorize a feature, based on the idea that its better to have many neurons contribute to the network output than a few.\n",
    "- there are two types of regularization L1 and L2, and they follow a general form of adding a penatly gradient to the gradient of loss wrt layer's weights and biases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fowrwad pass:\n",
    "- L1 - absolute value of the weights or bias times a penalty hyperparamter lamda added to the loss function. In our implementation, we sum all the weights/bias for a layer and multiply the lambda hyper parameter to that sum. Just increases loss by the abs value of the weight/bias. Please note that this is to calculate loss of total function, in backward pass penalty gradient is calculated on parameter level. Formula = lambda * sum(abs(weights)); weights = weights in layer, replace weights with bias for bias form\n",
    "- L2 - squared value of the weight/bias. This is summed up for all the weights/bias in layer. Adds penatly that scales with the weight, penalizing larger weights, and not affecting smaller weights as much. weight^2 (or bias) impact on loss. Formula = lambda * sum(weights^2); weights = weights in layer, replace weights with bias for bias form. Again, please note that this is for the loss value for the whole network, not derivative of layer.\n",
    "- the non-linear impact of L2 regularization impacts smaller weights less and larger weights more. the linear nature of L1 regularization impacts small weights more and can cause a model to become invariant to small values, and variant only to larger values. (i.e., because you are adding a constant value in L1, it is relatively larger to smaller weight values, having a much greater impact on pushing them to 0). As such L2 regularization is used more often than L1, and L1 is rarely used on its own.\n",
    "- lambda is the penalty scalar that dicates how strong the penalty is\n",
    "- in our implementation we set lambda independently for each layer. This is a more efficient solution, per chat GPT, as it would be a lot to set individual lambdas, but still maintains flexibility. It is simpler and more interpretable.\n",
    "- regularization drives model parameters closer to 0, thus forcing the network to not memorize the data, because as mentioned previosuly, very high weight/bias can mean the network is memorizing. It does this by increasing loss in the first degree and in the second degree, causing bigger steps towards 0 during backprop, expanded upon in following notes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updated Loss Class\n",
    "- added in summing up the loss for the whole network\n",
    "- pass a layer object to the regularization_loss function and it will accumulate the total regularization loss for the layer\n",
    "- outside this object in the broader training loop, the total regularization loss for each layer is calculated in the: regularization_loss = loss_activation.loss.regularization_loss(dense1) + loss_activation.loss.regularization_loss(dense2)\n",
    "- then they are summed together into the total loss: loss = data_loss + regularization_loss; which we capture in the graph and training print outs\n",
    "- please note that we have not included the layer regularization loss code, as the regularization loss for the layer is calculated in this funtion, not in the layer object. The layer object is used for the backward pass of the loss and to initialize loss parameters for the layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class Loss:\n",
    "# Regularization loss calculation\n",
    "    def regularization_loss(self, layer):\n",
    "    # 0 by default\n",
    "        regularization_loss = 0\n",
    "        # L1 regularization - weights\n",
    "        # calculate only when factor greater than 0\n",
    "        if layer.weight_regularizer_l1 > 0:\n",
    "            regularization_loss += layer.weight_regularizer_l1 * np.sum(np.abs(layer.weights))\n",
    "        # L2 regularization - weights\n",
    "        if layer.weight_regularizer_l2 > 0:\n",
    "            regularization_loss += layer.weight_regularizer_l2 * np.sum(layer.weights * layer.weights)\n",
    "        # L1 regularization - biases\n",
    "        # calculate only when factor greater than 0\n",
    "        if layer.bias_regularizer_l1 > 0:\n",
    "            regularization_loss += layer.bias_regularizer_l1 * np.sum(np.abs(layer.biases))\n",
    "        # L2 regularization - biases\n",
    "        if layer.bias_regularizer_l2 > 0:\n",
    "            regularization_loss += layer.bias_regularizer_l2 * np.sum(layer.biases * layer.biases)\n",
    "        return regularization_loss\n",
    "# Calculates the data and regularization losses\n",
    "# given model output and ground truth values\n",
    "    def calculate(self, output, y):\n",
    "        # Calculate sample losses\n",
    "        sample_losses = self.forward(output, y)\n",
    "        # Calculate mean loss\n",
    "        data_loss = np.mean(sample_losses)\n",
    "        # Return loss\n",
    "        return data_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backward pass:\n",
    "- Derivative of L1 Regularization wrt to weight: reminder, L1 is abs value of weight. so f(x) = abs(x); derivative of absolute value is 1 when x > 0, undefined at 0, and -1 when x < 0. Just think about absolute value curve. It is 1:1 upward sloping for positive values and -1:1 on negative values. Undefined at 0 because it is a corner. So full derivative of f(x) = lambda * abs(x); f'(x) = lambda * {1 if x > 0, -1 if x < 0}. In our code implementation, because we cannot have undefined, derivative of 0s will be 1. L1 derivative value is added to the derivative of the loss wrt to weight, so we will be adding positive or negative lambda to the derivative of loss wrt to the specific weight\n",
    "- derivative of L2 regulariztion wrt to weight: L2 regularization formula: f(x) = lambda*x^2; f'(x) = 2 * lambda * x. In code, we will add 2*lambda*weight to the derivative of the loss wrt to that weight\n",
    "- please note that for the backward pass, each weight is getting its own specific regularization derivative. This is unlike the forward pass where just add the accumulated regularization to the loss. Makes sense as since each weight is different, it should have a different regularization derivative.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our new layer backward pass function:\n",
    "- Please note that this omits the definition of the weight regularizer attributes on the instantiation of the object.\n",
    "- the weight regularizer variables l1, and l2 for weights and biases are the specific lambdas for each l1 and l2 for weights and biases \n",
    "- the if statments check if a particular regularizer variable (aka lambda) is not zero, i.e. greater than 0. If so, then it calculates the derivative and adds it to the actual weight derivatives of the weight variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(self, dvalues):\n",
    "    # Gradients on parameters\n",
    "    self.dweights = np.dot(self.inputs.T, dvalues)\n",
    "    self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
    "    # Gradients on regularization\n",
    "    # L1 on weights\n",
    "    if self.weight_regularizer_l1 > 0:\n",
    "        dL1 = np.ones_like(self.weights)\n",
    "        dL1[self.weights < 0] = -1\n",
    "        self.dweights += self.weight_regularizer_l1 * dL1\n",
    "    # L2 on weights\n",
    "    if self.weight_regularizer_l2 > 0:\n",
    "        self.dweights += 2 * self.weight_regularizer_l2 * self.weights\n",
    "        # L1 on biases\n",
    "    if self.bias_regularizer_l1 > 0:\n",
    "        dL1 = np.ones_like(self.biases)\n",
    "        dL1[self.biases < 0] = -1\n",
    "        self.dbiases += self.bias_regularizer_l1 * dL1\n",
    "    # L2 on biases\n",
    "    if self.bias_regularizer_l2 > 0:\n",
    "        self.dbiases += 2 * self.bias_regularizer_l2 * self.biases\n",
    "    # Gradient on values\n",
    "    self.dinputs = np.dot(dvalues, self.weights.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing out regulariztion\n",
    "- note please run cell at bottom of the workbook so that this works\n",
    "- this updates our print function as well to include normal loss, now \"data_loss\" and regularization loss now \"reg_loss\"\n",
    "- see how reg_loss is accumulated from the whole network\n",
    "- in this case we are doing l2 regularization to the first layer, with the same lambda on weights and biases\n",
    "- our validation loss improved from previous attempts: now it is .435 vs .858 pre-regularization, with same setting as previous attempt (this is not shown as we change some settings)\n",
    "- Note that the comment above is for 64 neurons and 100 training samples to compare to previous versions. What we show below increases to 512 neurons and 1000 training samples. This further decreases validation loss to:\n",
    "- increasing number of samples did not help, and actually lowered training accuracy and increased training loss, which told us we needed to increase the network size. This is a benefit of regularization - we can create larger models with less fear of overfitting/memorization\n",
    "- see the graphs in the book - with this larger network and more samples, the graph of the areas where the network assigns the colors of classes is much smoother and appears to be far more generalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 0.269, loss: 1.099 (data_loss: 1.099, reg_loss: 0.000), lr: 0.02\n",
      "epoch: 100, acc: 0.737, loss: 0.739 (data_loss: 0.679, reg_loss: 0.060), lr: 0.019999010049002574\n",
      "epoch: 200, acc: 0.811, loss: 0.572 (data_loss: 0.482, reg_loss: 0.090), lr: 0.019998010197985302\n",
      "epoch: 300, acc: 0.859, loss: 0.495 (data_loss: 0.395, reg_loss: 0.100), lr: 0.019997010446938183\n",
      "epoch: 400, acc: 0.873, loss: 0.454 (data_loss: 0.355, reg_loss: 0.099), lr: 0.01999601079584623\n",
      "epoch: 500, acc: 0.880, loss: 0.429 (data_loss: 0.333, reg_loss: 0.096), lr: 0.01999501124469445\n",
      "epoch: 600, acc: 0.888, loss: 0.410 (data_loss: 0.316, reg_loss: 0.093), lr: 0.01999401179346786\n",
      "epoch: 700, acc: 0.892, loss: 0.394 (data_loss: 0.305, reg_loss: 0.089), lr: 0.01999301244215147\n",
      "epoch: 800, acc: 0.891, loss: 0.386 (data_loss: 0.300, reg_loss: 0.086), lr: 0.0199920131907303\n",
      "epoch: 900, acc: 0.892, loss: 0.376 (data_loss: 0.293, reg_loss: 0.083), lr: 0.019991014039189386\n",
      "epoch: 1000, acc: 0.896, loss: 0.368 (data_loss: 0.281, reg_loss: 0.087), lr: 0.019990014987513734\n",
      "epoch: 1100, acc: 0.898, loss: 0.360 (data_loss: 0.277, reg_loss: 0.083), lr: 0.01998901603568839\n",
      "epoch: 1200, acc: 0.900, loss: 0.353 (data_loss: 0.274, reg_loss: 0.080), lr: 0.019988017183698373\n",
      "epoch: 1300, acc: 0.900, loss: 0.349 (data_loss: 0.272, reg_loss: 0.077), lr: 0.01998701843152872\n",
      "epoch: 1400, acc: 0.898, loss: 0.349 (data_loss: 0.274, reg_loss: 0.075), lr: 0.019986019779164473\n",
      "epoch: 1500, acc: 0.899, loss: 0.344 (data_loss: 0.271, reg_loss: 0.073), lr: 0.019985021226590672\n",
      "epoch: 1600, acc: 0.899, loss: 0.336 (data_loss: 0.264, reg_loss: 0.072), lr: 0.01998402277379235\n",
      "epoch: 1700, acc: 0.903, loss: 0.329 (data_loss: 0.259, reg_loss: 0.070), lr: 0.01998302442075457\n",
      "epoch: 1800, acc: 0.903, loss: 0.326 (data_loss: 0.258, reg_loss: 0.068), lr: 0.019982026167462367\n",
      "epoch: 1900, acc: 0.902, loss: 0.325 (data_loss: 0.258, reg_loss: 0.067), lr: 0.019981028013900805\n",
      "epoch: 2000, acc: 0.902, loss: 0.319 (data_loss: 0.253, reg_loss: 0.065), lr: 0.019980029960054924\n",
      "epoch: 2100, acc: 0.904, loss: 0.315 (data_loss: 0.251, reg_loss: 0.064), lr: 0.019979032005909798\n",
      "epoch: 2200, acc: 0.903, loss: 0.316 (data_loss: 0.254, reg_loss: 0.063), lr: 0.01997803415145048\n",
      "epoch: 2300, acc: 0.896, loss: 0.351 (data_loss: 0.272, reg_loss: 0.079), lr: 0.019977036396662037\n",
      "epoch: 2400, acc: 0.903, loss: 0.330 (data_loss: 0.255, reg_loss: 0.075), lr: 0.019976038741529537\n",
      "epoch: 2500, acc: 0.904, loss: 0.324 (data_loss: 0.252, reg_loss: 0.072), lr: 0.01997504118603805\n",
      "epoch: 2600, acc: 0.903, loss: 0.321 (data_loss: 0.250, reg_loss: 0.070), lr: 0.01997404373017264\n",
      "epoch: 2700, acc: 0.905, loss: 0.317 (data_loss: 0.249, reg_loss: 0.068), lr: 0.0199730463739184\n",
      "epoch: 2800, acc: 0.906, loss: 0.315 (data_loss: 0.248, reg_loss: 0.067), lr: 0.019972049117260395\n",
      "epoch: 2900, acc: 0.906, loss: 0.312 (data_loss: 0.247, reg_loss: 0.065), lr: 0.019971051960183714\n",
      "epoch: 3000, acc: 0.906, loss: 0.309 (data_loss: 0.246, reg_loss: 0.064), lr: 0.019970054902673444\n",
      "epoch: 3100, acc: 0.906, loss: 0.307 (data_loss: 0.245, reg_loss: 0.062), lr: 0.019969057944714663\n",
      "epoch: 3200, acc: 0.906, loss: 0.306 (data_loss: 0.245, reg_loss: 0.061), lr: 0.019968061086292475\n",
      "epoch: 3300, acc: 0.905, loss: 0.306 (data_loss: 0.246, reg_loss: 0.060), lr: 0.019967064327391967\n",
      "epoch: 3400, acc: 0.901, loss: 0.307 (data_loss: 0.248, reg_loss: 0.059), lr: 0.019966067667998237\n",
      "epoch: 3500, acc: 0.903, loss: 0.304 (data_loss: 0.246, reg_loss: 0.058), lr: 0.019965071108096383\n",
      "epoch: 3600, acc: 0.903, loss: 0.303 (data_loss: 0.246, reg_loss: 0.057), lr: 0.01996407464767152\n",
      "epoch: 3700, acc: 0.903, loss: 0.300 (data_loss: 0.243, reg_loss: 0.056), lr: 0.019963078286708732\n",
      "epoch: 3800, acc: 0.901, loss: 0.298 (data_loss: 0.243, reg_loss: 0.056), lr: 0.019962082025193145\n",
      "epoch: 3900, acc: 0.902, loss: 0.299 (data_loss: 0.244, reg_loss: 0.055), lr: 0.019961085863109868\n",
      "epoch: 4000, acc: 0.904, loss: 0.295 (data_loss: 0.241, reg_loss: 0.054), lr: 0.019960089800444013\n",
      "epoch: 4100, acc: 0.908, loss: 0.288 (data_loss: 0.235, reg_loss: 0.053), lr: 0.019959093837180697\n",
      "epoch: 4200, acc: 0.909, loss: 0.290 (data_loss: 0.237, reg_loss: 0.053), lr: 0.01995809797330505\n",
      "epoch: 4300, acc: 0.904, loss: 0.295 (data_loss: 0.242, reg_loss: 0.052), lr: 0.01995710220880218\n",
      "epoch: 4400, acc: 0.907, loss: 0.288 (data_loss: 0.236, reg_loss: 0.052), lr: 0.019956106543657228\n",
      "epoch: 4500, acc: 0.908, loss: 0.289 (data_loss: 0.238, reg_loss: 0.051), lr: 0.019955110977855316\n",
      "epoch: 4600, acc: 0.906, loss: 0.285 (data_loss: 0.235, reg_loss: 0.050), lr: 0.01995411551138158\n",
      "epoch: 4700, acc: 0.907, loss: 0.288 (data_loss: 0.239, reg_loss: 0.050), lr: 0.019953120144221154\n",
      "epoch: 4800, acc: 0.907, loss: 0.288 (data_loss: 0.238, reg_loss: 0.049), lr: 0.019952124876359174\n",
      "epoch: 4900, acc: 0.907, loss: 0.285 (data_loss: 0.237, reg_loss: 0.049), lr: 0.01995112970778079\n",
      "epoch: 5000, acc: 0.908, loss: 0.278 (data_loss: 0.230, reg_loss: 0.048), lr: 0.019950134638471142\n",
      "epoch: 5100, acc: 0.909, loss: 0.278 (data_loss: 0.231, reg_loss: 0.048), lr: 0.019949139668415376\n",
      "epoch: 5200, acc: 0.907, loss: 0.279 (data_loss: 0.231, reg_loss: 0.047), lr: 0.01994814479759864\n",
      "epoch: 5300, acc: 0.907, loss: 0.280 (data_loss: 0.233, reg_loss: 0.047), lr: 0.019947150026006097\n",
      "epoch: 5400, acc: 0.904, loss: 0.318 (data_loss: 0.251, reg_loss: 0.067), lr: 0.019946155353622895\n",
      "epoch: 5500, acc: 0.908, loss: 0.298 (data_loss: 0.238, reg_loss: 0.060), lr: 0.019945160780434196\n",
      "epoch: 5600, acc: 0.910, loss: 0.292 (data_loss: 0.235, reg_loss: 0.057), lr: 0.019944166306425162\n",
      "epoch: 5700, acc: 0.909, loss: 0.289 (data_loss: 0.233, reg_loss: 0.056), lr: 0.01994317193158096\n",
      "epoch: 5800, acc: 0.907, loss: 0.286 (data_loss: 0.232, reg_loss: 0.055), lr: 0.019942177655886757\n",
      "epoch: 5900, acc: 0.909, loss: 0.284 (data_loss: 0.230, reg_loss: 0.054), lr: 0.019941183479327725\n",
      "epoch: 6000, acc: 0.911, loss: 0.282 (data_loss: 0.229, reg_loss: 0.053), lr: 0.019940189401889033\n",
      "epoch: 6100, acc: 0.910, loss: 0.280 (data_loss: 0.228, reg_loss: 0.052), lr: 0.01993919542355587\n",
      "epoch: 6200, acc: 0.909, loss: 0.281 (data_loss: 0.230, reg_loss: 0.051), lr: 0.019938201544313403\n",
      "epoch: 6300, acc: 0.910, loss: 0.282 (data_loss: 0.232, reg_loss: 0.050), lr: 0.01993720776414682\n",
      "epoch: 6400, acc: 0.908, loss: 0.281 (data_loss: 0.232, reg_loss: 0.050), lr: 0.019936214083041307\n",
      "epoch: 6500, acc: 0.908, loss: 0.282 (data_loss: 0.233, reg_loss: 0.049), lr: 0.01993522050098206\n",
      "epoch: 6600, acc: 0.911, loss: 0.273 (data_loss: 0.225, reg_loss: 0.048), lr: 0.019934227017954262\n",
      "epoch: 6700, acc: 0.911, loss: 0.273 (data_loss: 0.225, reg_loss: 0.048), lr: 0.01993323363394311\n",
      "epoch: 6800, acc: 0.907, loss: 0.278 (data_loss: 0.231, reg_loss: 0.047), lr: 0.0199322403489338\n",
      "epoch: 6900, acc: 0.909, loss: 0.274 (data_loss: 0.227, reg_loss: 0.047), lr: 0.019931247162911534\n",
      "epoch: 7000, acc: 0.911, loss: 0.269 (data_loss: 0.223, reg_loss: 0.046), lr: 0.019930254075861523\n",
      "epoch: 7100, acc: 0.910, loss: 0.271 (data_loss: 0.225, reg_loss: 0.046), lr: 0.019929261087768962\n",
      "epoch: 7200, acc: 0.906, loss: 0.274 (data_loss: 0.229, reg_loss: 0.045), lr: 0.01992826819861907\n",
      "epoch: 7300, acc: 0.909, loss: 0.270 (data_loss: 0.225, reg_loss: 0.045), lr: 0.019927275408397054\n",
      "epoch: 7400, acc: 0.910, loss: 0.266 (data_loss: 0.222, reg_loss: 0.044), lr: 0.019926282717088132\n",
      "epoch: 7500, acc: 0.911, loss: 0.265 (data_loss: 0.221, reg_loss: 0.044), lr: 0.01992529012467752\n",
      "epoch: 7600, acc: 0.910, loss: 0.268 (data_loss: 0.225, reg_loss: 0.044), lr: 0.019924297631150445\n",
      "epoch: 7700, acc: 0.908, loss: 0.274 (data_loss: 0.231, reg_loss: 0.043), lr: 0.019923305236492123\n",
      "epoch: 7800, acc: 0.909, loss: 0.267 (data_loss: 0.224, reg_loss: 0.043), lr: 0.01992231294068779\n",
      "epoch: 7900, acc: 0.910, loss: 0.262 (data_loss: 0.219, reg_loss: 0.042), lr: 0.019921320743722666\n",
      "epoch: 8000, acc: 0.908, loss: 0.267 (data_loss: 0.225, reg_loss: 0.042), lr: 0.019920328645582\n",
      "epoch: 8100, acc: 0.906, loss: 0.269 (data_loss: 0.227, reg_loss: 0.042), lr: 0.019919336646251007\n",
      "epoch: 8200, acc: 0.872, loss: 0.394 (data_loss: 0.332, reg_loss: 0.062), lr: 0.019918344745714942\n",
      "epoch: 8300, acc: 0.912, loss: 0.282 (data_loss: 0.226, reg_loss: 0.056), lr: 0.019917352943959042\n",
      "epoch: 8400, acc: 0.911, loss: 0.279 (data_loss: 0.225, reg_loss: 0.053), lr: 0.019916361240968555\n",
      "epoch: 8500, acc: 0.912, loss: 0.276 (data_loss: 0.224, reg_loss: 0.052), lr: 0.01991536963672872\n",
      "epoch: 8600, acc: 0.911, loss: 0.274 (data_loss: 0.224, reg_loss: 0.051), lr: 0.019914378131224802\n",
      "epoch: 8700, acc: 0.912, loss: 0.272 (data_loss: 0.223, reg_loss: 0.050), lr: 0.01991338672444204\n",
      "epoch: 8800, acc: 0.911, loss: 0.271 (data_loss: 0.222, reg_loss: 0.049), lr: 0.0199123954163657\n",
      "epoch: 8900, acc: 0.911, loss: 0.270 (data_loss: 0.222, reg_loss: 0.048), lr: 0.019911404206981037\n",
      "epoch: 9000, acc: 0.910, loss: 0.270 (data_loss: 0.223, reg_loss: 0.047), lr: 0.019910413096273318\n",
      "epoch: 9100, acc: 0.913, loss: 0.268 (data_loss: 0.221, reg_loss: 0.047), lr: 0.019909422084227805\n",
      "epoch: 9200, acc: 0.910, loss: 0.268 (data_loss: 0.222, reg_loss: 0.046), lr: 0.019908431170829768\n",
      "epoch: 9300, acc: 0.912, loss: 0.268 (data_loss: 0.223, reg_loss: 0.045), lr: 0.01990744035606448\n",
      "epoch: 9400, acc: 0.913, loss: 0.269 (data_loss: 0.224, reg_loss: 0.045), lr: 0.01990644963991721\n",
      "epoch: 9500, acc: 0.911, loss: 0.266 (data_loss: 0.221, reg_loss: 0.044), lr: 0.01990545902237324\n",
      "epoch: 9600, acc: 0.909, loss: 0.269 (data_loss: 0.225, reg_loss: 0.044), lr: 0.019904468503417844\n",
      "epoch: 9700, acc: 0.914, loss: 0.262 (data_loss: 0.219, reg_loss: 0.043), lr: 0.019903478083036316\n",
      "epoch: 9800, acc: 0.911, loss: 0.271 (data_loss: 0.228, reg_loss: 0.043), lr: 0.019902487761213932\n",
      "epoch: 9900, acc: 0.913, loss: 0.263 (data_loss: 0.220, reg_loss: 0.042), lr: 0.019901497537935988\n",
      "epoch: 10000, acc: 0.913, loss: 0.259 (data_loss: 0.217, reg_loss: 0.042), lr: 0.019900507413187767\n"
     ]
    }
   ],
   "source": [
    "# Create dataset\n",
    "X, y = spiral_data(samples=1000, classes=3)\n",
    "# Create Dense layer with 2 input features and 64 output values\n",
    "dense1 = Layer_Dense(2, 512, weight_regularizer_l2=5e-4,\n",
    "bias_regularizer_l2=5e-4)\n",
    "# Create ReLU activation (to be used with Dense layer):\n",
    "activation1 = Activation_ReLU()\n",
    "# Create second Dense layer with 64 input features (as we take output\n",
    "# of previous layer here) and 3 output values (output values)\n",
    "dense2 = Layer_Dense(512, 3)\n",
    "# Create Softmax classifier's combined loss and activation\n",
    "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
    "# Create optimizer\n",
    "optimizer = Optimizer_Adam(learning_rate=0.02, decay=5e-7)\n",
    "# Train in loop\n",
    "for epoch in range(10001):\n",
    "    # Perform a forward pass of our training data through this layer\n",
    "    dense1.forward(X)\n",
    "    \n",
    "    # Perform a forward pass through activation function\n",
    "    # takes the output of first dense layer here\n",
    "    activation1.forward(dense1.output)\n",
    "\n",
    "    # Perform a forward pass through second Dense layer\n",
    "    # takes outputs of activation function of first layer as inputs\n",
    "    dense2.forward(activation1.output)\n",
    "    \n",
    "    # Perform a forward pass through the activation/loss function\n",
    "    # takes the output of second dense layer here and returns loss\n",
    "    data_loss = loss_activation.forward(dense2.output, y)\n",
    "    \n",
    "    # Calculate regularization penalty\n",
    "    regularization_loss = loss_activation.loss.regularization_loss(dense1) + loss_activation.loss.regularization_loss(dense2)\n",
    "    \n",
    "    # Calculate overall loss\n",
    "    loss = data_loss + regularization_loss\n",
    "    \n",
    "    # Calculate accuracy from output of activation2 and targets\n",
    "    # calculate values along first axis\n",
    "    predictions = np.argmax(loss_activation.output, axis=1)\n",
    "    if len(y.shape) == 2:\n",
    "        y = np.argmax(y, axis=1)\n",
    "    accuracy = np.mean(predictions == y)\n",
    "    \n",
    "    if not epoch % 100:\n",
    "        print(f'epoch: {epoch}, ' +\n",
    "        f'acc: {accuracy:.3f}, ' +\n",
    "        f'loss: {loss:.3f} (' +\n",
    "        f'data_loss: {data_loss:.3f}, ' +\n",
    "        f'reg_loss: {regularization_loss:.3f}), ' +\n",
    "        f'lr: {optimizer.current_learning_rate}')\n",
    "\n",
    "    # Backward pass\n",
    "    loss_activation.backward(loss_activation.output, y)\n",
    "    dense2.backward(loss_activation.dinputs)\n",
    "    activation1.backward(dense2.dinputs)\n",
    "    dense1.backward(activation1.dinputs)\n",
    "    # Update weights and biases\n",
    "    optimizer.pre_update_params()\n",
    "    optimizer.update_params(dense1)\n",
    "    optimizer.update_params(dense2)\n",
    "    optimizer.post_update_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation\n",
    "- our validation loss improved from previous attempts: now it is .435 vs .858 pre-regularization, with same setting as previous attempt (this is not shown as we change some settings)\n",
    "- but if we increase the number of neurons in the layer to 512 and increase the number of training samples to 1000, then we see additional improvement in validation loss to 0.256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation, acc: 0.897, loss: 0.278\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = spiral_data(samples=1000, classes=3)\n",
    "# Perform a forward pass of our testing data through this layer\n",
    "dense1.forward(X_test)\n",
    "# Perform a forward pass through activation function\n",
    "# takes the output of first dense layer here\n",
    "activation1.forward(dense1.output)\n",
    "# Perform a forward pass through second Dense layer\n",
    "# takes outputs of activation function of first layer as inputs\n",
    "dense2.forward(activation1.output)\n",
    "# Perform a forward pass through the activation/loss function\n",
    "# takes the output of second dense layer here and returns loss\n",
    "loss = loss_activation.forward(dense2.output, y_test)\n",
    "# Calculate accuracy from output of activation2 and targets\n",
    "# calculate values along first axis\n",
    "predictions = np.argmax(loss_activation.output, axis=1)\n",
    "if len(y_test.shape) == 2:\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "print(f'validation, acc: {accuracy:.3f}, loss: {loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network Objects Up to this point\n",
    "- adds in the new layer backward pass and intializtion parameters\n",
    "- adds in the new loss class and regularization loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "nnfs.init()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dense layer\n",
    "class Layer_Dense:\n",
    "    # Layer initialization\n",
    "    def __init__(self, n_inputs, n_neurons, weight_regularizer_l1=0, weight_regularizer_l2=0, \n",
    "                 bias_regularizer_l1=0, bias_regularizer_l2=0):\n",
    "        \n",
    "        # Initialize weights and biases\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "        # Set regularization strength\n",
    "        self.weight_regularizer_l1 = weight_regularizer_l1\n",
    "        self.weight_regularizer_l2 = weight_regularizer_l2\n",
    "        self.bias_regularizer_l1 = bias_regularizer_l1\n",
    "        self.bias_regularizer_l2 = bias_regularizer_l2\n",
    "    \n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "        # Calculate output values from input ones, weights and biases\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Gradients on parameters\n",
    "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
    "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
    "        # Gradients on regularization\n",
    "        # L1 on weights\n",
    "        if self.weight_regularizer_l1 > 0:\n",
    "            dL1 = np.ones_like(self.weights)\n",
    "            dL1[self.weights < 0] = -1\n",
    "            self.dweights += self.weight_regularizer_l1 * dL1\n",
    "        # L2 on weights\n",
    "        if self.weight_regularizer_l2 > 0:\n",
    "            self.dweights += 2 * self.weight_regularizer_l2 * self.weights\n",
    "            # L1 on biases\n",
    "        if self.bias_regularizer_l1 > 0:\n",
    "            dL1 = np.ones_like(self.biases)\n",
    "            dL1[self.biases < 0] = -1\n",
    "            self.dbiases += self.bias_regularizer_l1 * dL1\n",
    "        # L2 on biases\n",
    "        if self.bias_regularizer_l2 > 0:\n",
    "            self.dbiases += 2 * self.bias_regularizer_l2 * self.biases\n",
    "        # Gradient on values\n",
    "        self.dinputs = np.dot(dvalues, self.weights.T)\n",
    "\n",
    "# ReLU activation\n",
    "class Activation_ReLU:\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        # Calculate output values from inputs\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "    def backward(self, dvalues):\n",
    "        # Since we need to modify original variable,\n",
    "        # letâ€™s make a copy of values first\n",
    "        self.dinputs = dvalues.copy()\n",
    "        # Zero gradient where input values were negative\n",
    "        self.dinputs[self.inputs <= 0] = 0\n",
    "\n",
    "# Softmax activation\n",
    "class Activation_Softmax:\n",
    "# Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "        \n",
    "        # Get unnormalized probabilities\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "        \n",
    "        # Normalize them for each sample\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "        \n",
    "        self.output = probabilities\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Create uninitialized array\n",
    "        self.dinputs = np.empty_like(dvalues)\n",
    "        # Enumerate outputs and gradients\n",
    "        for index, (single_output, single_dvalues) in enumerate(zip(self.output, dvalues)):\n",
    "            # Flatten output array\n",
    "            single_output = single_output.reshape(-1, 1)\n",
    "            # Calculate Jacobian matrix of the output\n",
    "            jacobian_matrix = np.diagflat(single_output) - np.dot(single_output, single_output.T)\n",
    "            # Calculate sample-wise gradient\n",
    "            # and add it to the array of sample gradients\n",
    "            self.dinputs[index] = np.dot(jacobian_matrix, single_dvalues)\n",
    "\n",
    "# Common loss class\n",
    "class Loss:\n",
    "# Regularization loss calculation\n",
    "    def regularization_loss(self, layer):\n",
    "    # 0 by default\n",
    "        regularization_loss = 0\n",
    "        # L1 regularization - weights\n",
    "        # calculate only when factor greater than 0\n",
    "        if layer.weight_regularizer_l1 > 0:\n",
    "            regularization_loss += layer.weight_regularizer_l1 * np.sum(np.abs(layer.weights))\n",
    "        # L2 regularization - weights\n",
    "        if layer.weight_regularizer_l2 > 0:\n",
    "            regularization_loss += layer.weight_regularizer_l2 * np.sum(layer.weights * layer.weights)\n",
    "        # L1 regularization - biases\n",
    "        # calculate only when factor greater than 0\n",
    "        if layer.bias_regularizer_l1 > 0:\n",
    "            regularization_loss += layer.bias_regularizer_l1 * np.sum(np.abs(layer.biases))\n",
    "        # L2 regularization - biases\n",
    "        if layer.bias_regularizer_l2 > 0:\n",
    "            regularization_loss += layer.bias_regularizer_l2 * np.sum(layer.biases * layer.biases)\n",
    "        return regularization_loss\n",
    "    # Calculates the data and regularization losses\n",
    "    # given model output and ground truth values\n",
    "    def calculate(self, output, y):\n",
    "        # Calculate sample losses\n",
    "        sample_losses = self.forward(output, y)\n",
    "        # Calculate mean loss\n",
    "        data_loss = np.mean(sample_losses)\n",
    "        # Return loss\n",
    "        return data_loss\n",
    "        \n",
    "class Loss_CategoricalCrossentropy(Loss):\n",
    "# Forward pass\n",
    "    def forward(self, y_pred, y_true):\n",
    "    # Number of samples in a batch\n",
    "        samples = len(y_pred)\n",
    "        \n",
    "        # Clip data to prevent division by 0\n",
    "        # Clip both sides to not drag mean towards any value\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "        # Probabilities for target values -\n",
    "        # only if categorical labels\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[range(samples),y_true]\n",
    "        # Mask values - only for one-hot encoded labels\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum(y_pred_clipped * y_true, axis=1)\n",
    "        # Losses\n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "        return negative_log_likelihoods\n",
    "    \n",
    "    def backward(self, dvalues, y_true):\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "        # Number of labels in every sample\n",
    "        # We'll use the first sample to count them\n",
    "        labels = len(dvalues[0])\n",
    "        # If labels are sparse, turn them into one-hot vector\n",
    "        if len(y_true.shape) == 1:\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "        \n",
    "        # Calculate gradient\n",
    "        self.dinputs = -y_true / dvalues\n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples\n",
    "\n",
    "\n",
    "class Activation_Softmax_Loss_CategoricalCrossentropy():\n",
    "# Creates activation and loss function objects\n",
    "    def __init__(self):\n",
    "        self.activation = Activation_Softmax()\n",
    "        self.loss = Loss_CategoricalCrossentropy()\n",
    "        # Forward pass\n",
    "    def forward(self, inputs, y_true):\n",
    "        # Output layer's activation function\n",
    "        self.activation.forward(inputs)\n",
    "        # Set the output\n",
    "        self.output = self.activation.output\n",
    "        # Calculate and return loss value\n",
    "        return self.loss.calculate(self.output, y_true)\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "\n",
    "        # If labels are one-hot encoded,\n",
    "        # turn them into discrete values\n",
    "        if len(y_true.shape) == 2:\n",
    "            y_true = np.argmax(y_true, axis=1)\n",
    "        \n",
    "        # Copy so we can safely modify\n",
    "        self.dinputs = dvalues.copy()\n",
    "    \n",
    "        # For each row in dinputs, get what the network has for the correct class and subtract 1\n",
    "        self.dinputs[range(samples), y_true] -= 1\n",
    "        \n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples\n",
    "\n",
    "class Optimizer_SGD:\n",
    "# Initialize optimizer - set settings,\n",
    "# learning rate of 1. is default for this optimizer\n",
    "    def __init__(self, learning_rate=1., decay=0., momentum=0.):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.momentum = momentum\n",
    "    # Call once before any parameter updates\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * (1. / (1. + self.decay*self.iterations))\n",
    "    # Update parameters\n",
    "    def update_params(self, layer):\n",
    "    # If we use momentum\n",
    "        if self.momentum:\n",
    "        # If layer does not contain momentum arrays, create them\n",
    "        # filled with zeros\n",
    "            if not hasattr(layer, 'weight_momentums'):\n",
    "                layer.weight_momentums = np.zeros_like(layer.weights)\n",
    "                # If there is no momentum array for weights\n",
    "                # The array doesn't exist for biases yet either.\n",
    "                layer.bias_momentums = np.zeros_like(layer.biases)\n",
    "            \n",
    "            # Build weight updates with momentum - take previous\n",
    "            # updates multiplied by retain factor and update with\n",
    "            # current gradients\n",
    "            weight_updates = self.momentum * layer.weight_momentums - self.current_learning_rate * layer.dweights\n",
    "            layer.weight_momentums = weight_updates\n",
    "            # Build bias updates\n",
    "            bias_updates = self.momentum * layer.bias_momentums - self.current_learning_rate * layer.dbiases\n",
    "            layer.bias_momentums = bias_updates\n",
    "\n",
    "        else:\n",
    "            weight_updates = -self.current_learning_rate * layer.dweights\n",
    "            bias_updates = -self.current_learning_rate * layer.dbiases\n",
    "\n",
    "        layer.weights += weight_updates\n",
    "        layer.biases += bias_updates\n",
    "\n",
    "    # Call once after any parameter updates\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1\n",
    "\n",
    "class Optimizer_Adagrad:\n",
    "# Initialize optimizer - set settings,\n",
    "# learning rate of 1. is default for this optimizer\n",
    "    def __init__(self, learning_rate=1., decay=0., epsilon=1e-7):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.epsilon = epsilon\n",
    "    # Call once before any parameter updates\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * (1. / (1. + self.decay*self.iterations))\n",
    "    # Update parameters\n",
    "    def update_params(self, layer):\n",
    "        # If layer does not contain cache arrays,\n",
    "        # create them filled with zeros\n",
    "        if not hasattr(layer, 'weight_cache'):\n",
    "            layer.weight_cache = np.zeros_like(layer.weights)\n",
    "            layer.bias_cache = np.zeros_like(layer.biases)\n",
    "        # Update cache with squared current gradients\n",
    "        layer.weight_cache += layer.dweights**2\n",
    "        layer.bias_cache += layer.dbiases**2\n",
    "        # Vanilla SGD parameter update + normalization\n",
    "        # with square rooted cache\n",
    "        layer.weights += -self.current_learning_rate * layer.dweights / (np.sqrt(layer.weight_cache) + self.epsilon)\n",
    "        layer.biases += -self.current_learning_rate * layer.dbiases / (np.sqrt(layer.bias_cache) + self.epsilon)\n",
    "\n",
    "    # Call once after any parameter updates\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1\n",
    "\n",
    "class Optimizer_RMSprop:\n",
    "# Initialize optimizer - set settings,\n",
    "# learning rate of 1. is default for this optimizer\n",
    "    def __init__(self, learning_rate=.001, decay=0., epsilon=1e-7, rho=.9):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.epsilon = epsilon\n",
    "        self.rho = rho\n",
    "    # Call once before any parameter updates\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * (1. / (1. + self.decay*self.iterations))\n",
    "    # Update parameters\n",
    "    def update_params(self, layer):\n",
    "        # If layer does not contain cache arrays,\n",
    "        # create them filled with zeros\n",
    "        if not hasattr(layer, 'weight_cache'):\n",
    "            layer.weight_cache = np.zeros_like(layer.weights)\n",
    "            layer.bias_cache = np.zeros_like(layer.biases)\n",
    "        # Update cache with squared current gradients\n",
    "        layer.weight_cache = self.rho * layer.weight_cache + (1 - self.rho) * layer.dweights**2\n",
    "        layer.bias_cache = self.rho * layer.bias_cache + (1 - self.rho) * layer.dbiases**2\n",
    "        # Vanilla SGD parameter update + normalization\n",
    "        # with square rooted cache\n",
    "        layer.weights += -self.current_learning_rate * layer.dweights / (np.sqrt(layer.weight_cache) + self.epsilon)\n",
    "        layer.biases += -self.current_learning_rate * layer.dbiases / (np.sqrt(layer.bias_cache) + self.epsilon)\n",
    "\n",
    "    # Call once after any parameter updates\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1\n",
    "\n",
    "class Optimizer_Adam:\n",
    "    # Initialize optimizer - set settings\n",
    "    def __init__(self, learning_rate=0.001, decay=0., epsilon=1e-7, beta_1=0.9, beta_2=0.999):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.epsilon = epsilon\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "    \n",
    "    # Call once before any parameter updates\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * (1. / (1. + self.decay * self.iterations))\n",
    "    \n",
    "    # Update parameters\n",
    "    def update_params(self, layer):\n",
    "    # If layer does not contain cache arrays,\n",
    "    # create them filled with zeros\n",
    "        if not hasattr(layer, 'weight_cache'):\n",
    "            layer.weight_momentums = np.zeros_like(layer.weights)\n",
    "            layer.weight_cache = np.zeros_like(layer.weights)\n",
    "            layer.bias_momentums = np.zeros_like(layer.biases)\n",
    "            layer.bias_cache = np.zeros_like(layer.biases)\n",
    "        \n",
    "        # Update momentum with current gradients\n",
    "        layer.weight_momentums = self.beta_1 * layer.weight_momentums + (1 - self.beta_1) * layer.dweights\n",
    "        layer.bias_momentums = self.beta_1 * layer.bias_momentums + (1 - self.beta_1) * layer.dbiases\n",
    "        \n",
    "        # Get corrected momentum\n",
    "        # self.iteration is 0 at first pass\n",
    "        # and we need to start with 1 here\n",
    "        weight_momentums_corrected = layer.weight_momentums / (1 - self.beta_1 ** (self.iterations + 1))\n",
    "        bias_momentums_corrected = layer.bias_momentums / (1 - self.beta_1 ** (self.iterations + 1))\n",
    "        \n",
    "        # Update cache with squared current gradients\n",
    "        layer.weight_cache = self.beta_2 * layer.weight_cache + (1 - self.beta_2) * layer.dweights**2\n",
    "\n",
    "        layer.bias_cache = self.beta_2 * layer.bias_cache + (1 - self.beta_2) * layer.dbiases**2\n",
    "        \n",
    "        # Get corrected cache\n",
    "        weight_cache_corrected = layer.weight_cache / (1 - self.beta_2 ** (self.iterations + 1))\n",
    "        bias_cache_corrected = layer.bias_cache / (1 - self.beta_2 ** (self.iterations + 1))\n",
    "        \n",
    "        # Vanilla SGD parameter update + normalization\n",
    "        # with square rooted cache\n",
    "        layer.weights += -self.current_learning_rate * weight_momentums_corrected / (np.sqrt(weight_cache_corrected) + self.epsilon)\n",
    "        layer.biases += -self.current_learning_rate * bias_momentums_corrected / (np.sqrt(bias_cache_corrected) + self.epsilon)\n",
    "    \n",
    "    # Call once after any parameter updates\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
